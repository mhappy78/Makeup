from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Tuple, Dict, Any
import io
import cv2
import numpy as np
from PIL import Image
import mediapipe as mp
import base64
import uuid
import os
import math
from datetime import datetime
import openai
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai.api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Face Simulator API",
    description="ì–¼êµ´ ì„±í˜• ì‹œë®¬ë ˆì´í„° ë°±ì—”ë“œ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Flutter ì›¹/ì•±ì—ì„œ ì ‘ê·¼ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MediaPipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# ì „ì—­ ë³€ìˆ˜
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=True,
    max_num_faces=10,  # ì—¬ëŸ¬ ì–¼êµ´ ê°ì§€ë¥¼ ìœ„í•´ ì¦ê°€
    refine_landmarks=True,
    min_detection_confidence=0.5
)

# ì„ì‹œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
TEMP_DIR = "temp_images"
os.makedirs(TEMP_DIR, exist_ok=True)

def cleanup_old_temp_files(max_age_hours: int = 24):
    """ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ë“¤ì„ ì •ë¦¬"""
    try:
        import time
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600
        
        for filename in os.listdir(TEMP_DIR):
            if filename.endswith(('.jpg', '.jpeg', '.png', '.webp')):
                file_path = os.path.join(TEMP_DIR, filename)
                file_age = current_time - os.path.getctime(file_path)
                
                if file_age > max_age_seconds:
                    try:
                        os.remove(file_path)
                    except OSError:
                        pass  # íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
    except Exception:
        pass  # ì •ë¦¬ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ (ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ)

def select_largest_face(multi_face_landmarks):
    """ì—¬ëŸ¬ ì–¼êµ´ ì¤‘ ê°€ì¥ í° ì–¼êµ´ì„ ì„ íƒ"""
    if not multi_face_landmarks:
        return None, False
    
    if len(multi_face_landmarks) == 1:
        return multi_face_landmarks[0], False
    
    # ì—¬ëŸ¬ ì–¼êµ´ì´ ìˆëŠ” ê²½ìš° ê°€ì¥ í° ì–¼êµ´ ì°¾ê¸°
    largest_face = None
    largest_area = 0
    
    for face_landmarks in multi_face_landmarks:
        # ì–¼êµ´ ê²½ê³„ ë°•ìŠ¤ ê³„ì‚°
        min_x = min([landmark.x for landmark in face_landmarks.landmark])
        max_x = max([landmark.x for landmark in face_landmarks.landmark])
        min_y = min([landmark.y for landmark in face_landmarks.landmark])
        max_y = max([landmark.y for landmark in face_landmarks.landmark])
        
        # ë©´ì  ê³„ì‚°
        area = (max_x - min_x) * (max_y - min_y)
        
        if area > largest_area:
            largest_area = area
            largest_face = face_landmarks
    
    return largest_face, True  # TrueëŠ” ì—¬ëŸ¬ ì–¼êµ´ì´ ìˆì—ˆìŒì„ ì˜ë¯¸

# Pydantic ëª¨ë¸ë“¤
class WarpRequest(BaseModel):
    image_id: str
    start_x: float
    start_y: float
    end_x: float
    end_y: float
    influence_radius: float = 80.0
    strength: float = 1.0
    mode: str = "pull"  # pull, push, expand, shrink

class PresetRequest(BaseModel):
    image_id: str
    preset_type: str  # lower_jaw, middle_jaw, cheek, front_protusion, back_slit

class LandmarkResponse(BaseModel):
    landmarks: List[Tuple[float, float]]
    image_width: int
    image_height: int
    warning_message: Optional[str] = None

class ImageResponse(BaseModel):
    image_id: str
    image_data: str  # base64 encoded

class BeautyComparisonRequest(BaseModel):
    before_analysis: Dict[str, Any]  # ì´ì „ ë·°í‹° ë¶„ì„ ê²°ê³¼
    after_analysis: Dict[str, Any]   # í˜„ì¬ ë·°í‹° ë¶„ì„ ê²°ê³¼

class BeautyComparisonResponse(BaseModel):
    overall_change: str  # ì „ë°˜ì  ë³€í™” ("improved", "declined", "similar")
    score_changes: Dict[str, float]  # ê° í•­ëª©ë³„ ì ìˆ˜ ë³€í™”
    recommendations: List[str]  # GPT ì¶”ì²œì‚¬í•­
    analysis_text: str  # ìƒì„¸ ë¶„ì„ í…ìŠ¤íŠ¸

class InitialBeautyAnalysisRequest(BaseModel):
    beauty_analysis: Dict[str, Any]  # ë·°í‹° ë¶„ì„ ê²°ê³¼

class InitialBeautyAnalysisResponse(BaseModel):
    analysis_text: str  # ìƒì„¸ ë¶„ì„ í…ìŠ¤íŠ¸
    recommendations: List[str]  # GPT ì¶”ì²œì‚¬í•­

    
@app.get("/")
async def root():
    return {"message": "Face Simulator API", "status": "running"}

@app.post("/upload-image")
async def upload_image(file: UploadFile = File(...)):
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ID ë°˜í™˜"""
    try:
        # ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬ (24ì‹œê°„ ì´ìƒ)
        cleanup_old_temp_files(max_age_hours=1)
        
        # íŒŒì¼ ê²€ì¦
        if not file.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ID ìƒì„±
        image_id = str(uuid.uuid4())
        
        # íŒŒì¼ ì½ê¸° ë° ì €ì¥
        contents = await file.read()
        
        # OpenCVë¡œ ì´ë¯¸ì§€ ì½ê¸°
        nparr = np.frombuffer(contents, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if image is None:
            raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ íŒŒì¼ì…ë‹ˆë‹¤")
        
        # RGBë¡œ ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        cv2.imwrite(temp_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))
        
        # ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
        height, width = image_rgb.shape[:2]
        
        return {
            "image_id": image_id,
            "width": width,
            "height": height,
            "message": "ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@app.get("/landmarks/{image_id}")
async def get_face_landmarks(image_id: str):
    """ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(temp_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        height, width = image_rgb.shape[:2]
        
        # MediaPipeë¡œ ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
        results = face_mesh.process(image_rgb)
        
        if not results.multi_face_landmarks:
            raise HTTPException(status_code=404, detail="ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
        face_landmarks, has_multiple_faces = select_largest_face(results.multi_face_landmarks)
        
        if face_landmarks is None:
            raise HTTPException(status_code=404, detail="ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì—¬ëŸ¬ ì–¼êµ´ì´ ìˆì—ˆë‹¤ë©´ ê²½ê³  ë©”ì‹œì§€ í¬í•¨
        warning_message = None
        if has_multiple_faces:
            warning_message = f"ì—¬ëŸ¬ ëª…ì˜ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê°€ì¥ í° ì–¼êµ´ì„ ìë™ìœ¼ë¡œ ì„ íƒí–ˆìŠµë‹ˆë‹¤."
        
        # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ
        landmarks = []
        
        for landmark in face_landmarks.landmark:
            x = landmark.x * width
            y = landmark.y * height
            landmarks.append((x, y))
        
        return LandmarkResponse(
            landmarks=landmarks,
            image_width=width,
            image_height=height,
            warning_message=warning_message
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e) or "ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"ëœë“œë§ˆí¬ ê²€ì¶œ ì‹¤íŒ¨: {str(e)}")

@app.post("/warp-image")
async def warp_image(request: WarpRequest):
    """ì´ë¯¸ì§€ ì›Œí•‘(ììœ ë³€í˜•) ì ìš©"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{request.image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(temp_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì›Œí•‘ ì ìš©
        warped_image = apply_warp(
            image_rgb,
            start_x=request.start_x,
            start_y=request.start_y,
            end_x=request.end_x,
            end_y=request.end_y,
            influence_radius=request.influence_radius,
            strength=request.strength,
            mode=request.mode
        )
        
        # ìƒˆë¡œìš´ UUIDë¡œ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ (ì›ë³¸ ë³´ì¡´)
        new_image_id = str(uuid.uuid4())
        new_temp_path = os.path.join(TEMP_DIR, f"{new_image_id}.jpg")
        cv2.imwrite(new_temp_path, cv2.cvtColor(warped_image, cv2.COLOR_RGB2BGR))
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜
        pil_image = Image.fromarray(warped_image)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='JPEG', quality=95)
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        return ImageResponse(
            image_id=new_image_id,
            image_data=img_base64
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì›Œí•‘ ì‹¤íŒ¨: {str(e)}")

@app.get("/download-image/{image_id}")
async def download_image(image_id: str):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        def iterfile(file_path: str):
            with open(file_path, mode="rb") as file_like:
                yield from file_like
        
        return StreamingResponse(
            iterfile(temp_path),
            media_type="image/jpeg",
            headers={"Content-Disposition": f"attachment; filename=face_simulator_result_{image_id[:8]}.jpg"}
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@app.post("/apply-preset")
async def apply_preset(request: PresetRequest):
    """í”„ë¦¬ì…‹ ì ìš©"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{request.image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(temp_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
        results = face_mesh.process(image_rgb)
        
        if not results.multi_face_landmarks:
            raise HTTPException(status_code=404, detail="ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
        face_landmarks, has_multiple_faces = select_largest_face(results.multi_face_landmarks)
        
        if face_landmarks is None:
            raise HTTPException(status_code=404, detail="ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ
        height, width = image_rgb.shape[:2]
        landmarks = []
        
        for landmark in face_landmarks.landmark:
            x = landmark.x * width
            y = landmark.y * height
            landmarks.append((x, y))
        
        # í”„ë¦¬ì…‹ ì ìš©
        result_image = apply_preset_transformation(image_rgb, landmarks, request.preset_type)
        
        # ìƒˆë¡œìš´ UUIDë¡œ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        new_image_id = str(uuid.uuid4())
        new_temp_path = os.path.join(TEMP_DIR, f"{new_image_id}.jpg")
        cv2.imwrite(new_temp_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜
        pil_image = Image.fromarray(result_image)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='JPEG', quality=95)
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        return ImageResponse(
            image_id=new_image_id,
            image_data=img_base64
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e) or "ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"í”„ë¦¬ì…‹ ì ìš© ì‹¤íŒ¨: {str(e)}")

@app.delete("/image/{image_id}")
async def delete_image(image_id: str):
    """ì„ì‹œ ì´ë¯¸ì§€ ì‚­ì œ"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        
        if os.path.exists(temp_path):
            os.remove(temp_path)
            return {"message": "ì´ë¯¸ì§€ ì‚­ì œ ì„±ê³µ"}
        else:
            return {"message": "ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

@app.post("/analyze-beauty-comparison")
async def analyze_beauty_comparison(request: BeautyComparisonRequest):
    """ë·°í‹° ì ìˆ˜ ë³€í™” ë¶„ì„ ë° GPT ì¶”ì²œ"""
    try:
        before = request.before_analysis
        after = request.after_analysis
        
        # ì ìˆ˜ ë³€í™” ê³„ì‚°
        score_changes = {}
        if 'overallScore' in before and 'overallScore' in after:
            score_changes['overall'] = after['overallScore'] - before['overallScore']
        
        # ì„¸ë¶€ í•­ëª©ë³„ ë³€í™” (ëˆˆ/ì½”/ì…ìˆ  ì œì™¸)
        detail_items = ['verticalScore', 'horizontalScore', 'lowerFaceScore', 'symmetry', 'jawScore']
        for item in detail_items:
            if item in before and item in after:
                # ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì¸ ê²½ìš° 'score' í‚¤ì—ì„œ ê°’ ì¶”ì¶œ
                if isinstance(before[item], dict) and isinstance(after[item], dict):
                    before_score = before[item].get('score', 0)
                    after_score = after[item].get('score', 0)
                    calculated_change = after_score - before_score
                    
                    # í„± ê³¡ë¥ ì˜ ê²½ìš° ë³€í™”ê°€ 0.0ì´ë©´ ë‹¤ë¥¸ í•­ëª©ì˜ ë³€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
                    if item == 'jawScore' and abs(calculated_change) < 0.1:
                        # í•˜ê´€ ì¡°í™”ë‚˜ ì „ì²´ ëŒ€ì¹­ì„±ì´ ë³€í–ˆë‹¤ë©´ í„± ê³¡ë¥ ë„ ì˜í–¥ë°›ì•˜ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                        lower_face_change = score_changes.get('lowerFaceScore', 0)
                        symmetry_change = score_changes.get('symmetry', 0)
                        
                        if abs(lower_face_change) > 0.5 or abs(symmetry_change) > 0.5:
                            # í•˜ê´€ ì¡°í™”ë‚˜ ëŒ€ì¹­ì„± ë³€í™”ì˜ 30% ì •ë„ë¡œ í„± ê³¡ë¥  ë³€í™” ì¶”ì •
                            estimated_change = (lower_face_change + symmetry_change) * 0.3
                            score_changes[item] = max(-3.0, min(3.0, estimated_change))  # -3~+3 ë²”ìœ„ë¡œ ì œí•œ
                        else:
                            score_changes[item] = calculated_change
                    else:
                        score_changes[item] = calculated_change
                else:
                    # ìˆ«ì íƒ€ì…ì¸ ê²½ìš° ì§ì ‘ ê³„ì‚°
                    score_changes[item] = after[item] - before[item]
        
        # ì „ë°˜ì  ë³€í™” íŒë‹¨
        overall_change = "similar"
        if score_changes.get('overall', 0) > 2:
            overall_change = "improved"
        elif score_changes.get('overall', 0) < -2:
            overall_change = "declined"
        
        # GPT-4o minië¥¼ ì‚¬ìš©í•œ ë¶„ì„
        analysis_result = await get_gpt_beauty_analysis(before, after, score_changes)
        
        return BeautyComparisonResponse(
            overall_change=overall_change,
            score_changes=score_changes,
            recommendations=analysis_result["recommendations"],
            analysis_text=analysis_result["analysis"]
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë·°í‹° ë¶„ì„ ë¹„êµ ì‹¤íŒ¨: {str(e)}")

@app.post("/analyze-initial-beauty-score")
async def analyze_initial_beauty_score(request: InitialBeautyAnalysisRequest):
    """ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ GPT ë¶„ì„"""
    try:
        beauty_analysis = request.beauty_analysis
        
        # GPT-4o minië¥¼ ì‚¬ìš©í•œ ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ ë¶„ì„
        analysis_result = await get_gpt_initial_beauty_analysis(beauty_analysis)
        
        return InitialBeautyAnalysisResponse(
            analysis_text=analysis_result["analysis"],
            recommendations=analysis_result["recommendations"]
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}")


def apply_warp(image: np.ndarray, start_x: float, start_y: float, 
               end_x: float, end_y: float, influence_radius: float, 
               strength: float, mode: str) -> np.ndarray:
    """ì›Œí•‘ ë³€í˜• ì ìš© í•¨ìˆ˜"""
    img_height, img_width = image.shape[:2]
    
    # ì¢Œí‘œ ê²½ê³„ ê²€ì‚¬
    start_x = max(0, min(start_x, img_width - 1))
    start_y = max(0, min(start_y, img_height - 1))
    end_x = max(0, min(end_x, img_width - 1))
    end_y = max(0, min(end_y, img_height - 1))
    
    if mode == "pull":
        return apply_pull_warp(image, start_x, start_y, end_x, end_y, influence_radius, strength)
    elif mode == "push":
        return apply_push_warp(image, start_x, start_y, end_x, end_y, influence_radius, strength)
    elif mode == "expand":
        return apply_radial_warp(image, start_x, start_y, influence_radius, strength, expand=True)
    elif mode == "shrink":
        return apply_radial_warp(image, start_x, start_y, influence_radius, strength, expand=False)
    else:
        return image

def apply_pull_warp(image: np.ndarray, start_x: float, start_y: float,
                   end_x: float, end_y: float, influence_radius: float, strength: float, ellipse_ratio: float = None) -> np.ndarray:
    """ë‹¹ê¸°ê¸° ì›Œí•‘"""
    img_height, img_width = image.shape[:2]
    
    # ë“œë˜ê·¸ ë²¡í„° (ì˜ˆì „ ë°©ì‹: ë°˜ëŒ€ ë°©í–¥)
    dx = start_x - end_x
    dy = start_y - end_y
    
    # ë³€í˜• ë§µ ìƒì„±
    map_x = np.arange(img_width, dtype=np.float32).reshape(1, -1)
    map_y = np.arange(img_height, dtype=np.float32).reshape(-1, 1)
    map_x = np.repeat(map_x, img_height, axis=0)
    map_y = np.repeat(map_y, img_width, axis=1)
    
    # ê° í”½ì…€ì—ì„œ ì‹œì‘ì ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    pixel_dx = map_x - start_x
    pixel_dy = map_y - start_y
    pixel_dist = np.sqrt(pixel_dx*pixel_dx + pixel_dy*pixel_dy)
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­ ë§ˆìŠ¤í¬
    mask = pixel_dist < influence_radius
    
    # ë³€í˜• ê°•ë„ ê³„ì‚°
    strength_map = np.zeros_like(pixel_dist)
    valid_dist = pixel_dist[mask]
    
    if len(valid_dist) > 0:
        strength_map[mask] = (1 - valid_dist / influence_radius) ** 2
        strength_map[mask] *= strength
        
        # ë³€í˜• ì ìš©
        map_x[mask] += dx * strength_map[mask]
        map_y[mask] += dy * strength_map[mask]
    
    # ê²½ê³„ í´ë¦¬í•‘
    map_x = np.clip(map_x, 0, img_width - 1)
    map_y = np.clip(map_y, 0, img_height - 1)
    
    # ë¦¬ë§µí•‘ ì ìš©
    return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

def apply_push_warp(image: np.ndarray, start_x: float, start_y: float,
                   end_x: float, end_y: float, influence_radius: float, strength: float) -> np.ndarray:
    """ë°€ì–´ë‚´ê¸° ì›Œí•‘"""
    img_height, img_width = image.shape[:2]
    
    # ë“œë˜ê·¸ ë²¡í„°
    dx = end_x - start_x
    dy = end_y - start_y
    
    # ë³€í˜• ë§µ ìƒì„±
    map_x = np.arange(img_width, dtype=np.float32).reshape(1, -1)
    map_y = np.arange(img_height, dtype=np.float32).reshape(-1, 1)
    map_x = np.repeat(map_x, img_height, axis=0)
    map_y = np.repeat(map_y, img_width, axis=1)
    
    # ê° í”½ì…€ì—ì„œ ì‹œì‘ì ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    pixel_dx = map_x - start_x
    pixel_dy = map_y - start_y
    pixel_dist = np.sqrt(pixel_dx*pixel_dx + pixel_dy*pixel_dy)
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­ ë§ˆìŠ¤í¬
    mask = pixel_dist < influence_radius
    
    # ë³€í˜• ê°•ë„ ê³„ì‚°
    strength_map = np.zeros_like(pixel_dist)
    valid_dist = pixel_dist[mask]
    
    if len(valid_dist) > 0:
        strength_map[mask] = (1 - valid_dist / influence_radius) ** 2
        strength_map[mask] *= strength
        
        # ë³€í˜• ì ìš©
        map_x[mask] += dx * strength_map[mask]
        map_y[mask] += dy * strength_map[mask]
    
    # ê²½ê³„ í´ë¦¬í•‘
    map_x = np.clip(map_x, 0, img_width - 1)
    map_y = np.clip(map_y, 0, img_height - 1)
    
    # ë¦¬ë§µí•‘ ì ìš©
    return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)


def apply_radial_warp(image: np.ndarray, center_x: float, center_y: float,
                     influence_radius: float, strength: float, expand: bool = True) -> np.ndarray:
    """ë°©ì‚¬í˜• ì›Œí•‘ (í™•ëŒ€/ì¶•ì†Œ)"""
    img_height, img_width = image.shape[:2]
    
    # ë³€í˜• ë§µ ìƒì„±
    map_x = np.arange(img_width, dtype=np.float32).reshape(1, -1)
    map_y = np.arange(img_height, dtype=np.float32).reshape(-1, 1)
    map_x = np.repeat(map_x, img_height, axis=0)
    map_y = np.repeat(map_y, img_width, axis=1)
    
    # ì¤‘ì‹¬ì ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ì™€ ê°ë„
    dx = map_x - center_x
    dy = map_y - center_y
    distance = np.sqrt(dx*dx + dy*dy)
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­
    mask = distance < influence_radius
    
    # ë³€í˜• ê³„ìˆ˜ ê³„ì‚°
    strength_factor = strength * 0.3
    
    if expand:
        # í™•ëŒ€: ì¤‘ì‹¬ìœ¼ë¡œ ê°€ê¹Œì›Œì§€ê²Œ (íŒ½ì°½ íš¨ê³¼)
        scale_factor = 1 - strength_factor * (1 - distance / influence_radius)
    else:
        # ì¶•ì†Œ: ì¤‘ì‹¬ì—ì„œ ë©€ì–´ì§€ê²Œ (ìˆ˜ì¶• íš¨ê³¼)
        scale_factor = 1 + strength_factor * (1 - distance / influence_radius)
    
    scale_factor = np.maximum(scale_factor, 0.1)  # ìµœì†Œ ìŠ¤ì¼€ì¼ ì œí•œ
    
    # ìƒˆë¡œìš´ ì¢Œí‘œ ê³„ì‚°
    new_x = center_x + dx * scale_factor
    new_y = center_y + dy * scale_factor
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­ë§Œ ì—…ë°ì´íŠ¸
    map_x = np.where(mask, new_x, map_x)
    map_y = np.where(mask, new_y, map_y)
    
    # ê²½ê³„ í´ë¦¬í•‘
    map_x = np.clip(map_x, 0, img_width - 1)
    map_y = np.clip(map_y, 0, img_height - 1)
    
    # ë¦¬ë§µí•‘ ì ìš©
    return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)


def apply_preset_transformation(image: np.ndarray, landmarks: List[Tuple[float, float]], preset_type: str) -> np.ndarray:
    """í”„ë¦¬ì…‹ ë³€í˜• ì ìš©"""
    
    # í”„ë¦¬ì…‹ ìƒìˆ˜ë“¤ (face_simulator.pyì—ì„œ ê°€ì ¸ì˜´)
    PRESET_CONFIGS = {
        'lower_jaw': {
            'strength': 0.05,
            'influence_ratio': 0.4,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (150, 379, 4)
        },
        'middle_jaw': {
            'strength': 0.05,
            'influence_ratio': 0.65,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (172, 397, 4)
        },
        'cheek': {
            'strength': 0.05,
            'influence_ratio': 0.65,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (215, 435, 4)
        },
        'front_protusion': {
            'strength': 0.3,
            'influence_ratio': 0.1,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (243, 463, (56, 190), (414, 286), 168, 6),
            'ellipse_ratio': 1.3
        },
        'back_slit': {
            'strength': 0.5,
            'influence_ratio': 0.1,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (33, 359, (34, 162), (368, 264))
        }
    }
    
    if preset_type not in PRESET_CONFIGS:
        raise ValueError(f"Unknown preset type: {preset_type}")
    
    config = PRESET_CONFIGS[preset_type]
    
    # ì–¼êµ´ í¬ê¸° ê³„ì‚°
    face_size_left = landmarks[config['face_size_landmarks'][0]]
    face_size_right = landmarks[config['face_size_landmarks'][1]]
    face_width = abs(face_size_right[0] - face_size_left[0])
    
    
    # ì˜í–¥ ë°˜ê²½ ê³„ì‚°
    influence_radius = face_width * config['influence_ratio']
    
    result_image = image.copy()
    
    if preset_type in ['lower_jaw', 'middle_jaw', 'cheek']:
        # ê¸°ë³¸ í„±ì„  í”„ë¦¬ì…‹ (ì¢Œìš° ëŒ€ì¹­)
        left_landmark = landmarks[config['target_landmarks'][0]]
        right_landmark = landmarks[config['target_landmarks'][1]]
        target_landmark = landmarks[config['target_landmarks'][2]]
        
        # ì¢Œì¸¡ ë³€í˜•
        distance_left = math.sqrt((left_landmark[0] - target_landmark[0])**2 + 
                                (left_landmark[1] - target_landmark[1])**2)
        pull_distance_left = distance_left * config['pull_ratio']
        
        dx_left = target_landmark[0] - left_landmark[0]
        dy_left = target_landmark[1] - left_landmark[1]
        norm_left = math.sqrt(dx_left**2 + dy_left**2)
        
        if norm_left > 0:
            dx_left = (dx_left / norm_left) * pull_distance_left
            dy_left = (dy_left / norm_left) * pull_distance_left
            
            target_x_left = left_landmark[0] + dx_left
            target_y_left = left_landmark[1] + dy_left
            
            result_image = apply_pull_warp(
                result_image,
                left_landmark[0], left_landmark[1],
                target_x_left, target_y_left,
                influence_radius, config['strength']
            )
        
        # ìš°ì¸¡ ë³€í˜•
        distance_right = math.sqrt((right_landmark[0] - target_landmark[0])**2 + 
                                 (right_landmark[1] - target_landmark[1])**2)
        pull_distance_right = distance_right * config['pull_ratio']
        
        dx_right = target_landmark[0] - right_landmark[0]
        dy_right = target_landmark[1] - right_landmark[1]
        norm_right = math.sqrt(dx_right**2 + dy_right**2)
        
        if norm_right > 0:
            dx_right = (dx_right / norm_right) * pull_distance_right
            dy_right = (dy_right / norm_right) * pull_distance_right
            
            target_x_right = right_landmark[0] + dx_right
            target_y_right = right_landmark[1] + dy_right
            
            result_image = apply_pull_warp(
                result_image,
                right_landmark[0], right_landmark[1],
                target_x_right, target_y_right,
                influence_radius, config['strength']
            )
    
    elif preset_type == 'front_protusion':
        # ì•íŠ¸ì„ í”„ë¦¬ì…‹ (4ê°œ í¬ì¸íŠ¸)
        landmark_243 = landmarks[243]
        landmark_463 = landmarks[463]
        
        
        # ì¤‘ê°„ì ë“¤ ê³„ì‚°
        mid_56_190 = ((landmarks[56][0] + landmarks[190][0]) / 2,
                      (landmarks[56][1] + landmarks[190][1]) / 2)
        mid_414_286 = ((landmarks[414][0] + landmarks[286][0]) / 2,
                       (landmarks[414][1] + landmarks[286][1]) / 2)
        
        
        # ì•íŠ¸ì„: ì˜ˆì „ ë°©ì‹ - ì½” ì¤‘ì‹¬ìœ¼ë¡œ ë‹¹ê¸°ê¸°
        # íƒ€ê²Ÿ ì¤‘ê°„ì  ê³„ì‚° (168 + 6ì˜ ì¤‘ê°„ì )
        target_mid = ((landmarks[168][0] + landmarks[6][0]) / 2,
                      (landmarks[168][1] + landmarks[6][1]) / 2)
        
        
        # ê° í¬ì¸íŠ¸ì— ë³€í˜• ì ìš© (ì½” ì¤‘ì‹¬ìœ¼ë¡œ)
        for i, (source_landmark, target_point) in enumerate([
            (landmark_243, target_mid),
            (landmark_463, target_mid),
            (mid_56_190, target_mid),
            (mid_414_286, target_mid)
        ]):
            distance = math.sqrt((source_landmark[0] - target_point[0])**2 + 
                               (source_landmark[1] - target_point[1])**2)
            pull_distance = distance * config['pull_ratio']
            
            dx = target_point[0] - source_landmark[0]
            dy = target_point[1] - source_landmark[1]
            norm = math.sqrt(dx**2 + dy**2)
            
            
            if norm > 0:
                dx = (dx / norm) * pull_distance
                dy = (dy / norm) * pull_distance
                
                target_x = source_landmark[0] + dx
                target_y = source_landmark[1] + dy
                
                
                result_image = apply_pull_warp(
                    result_image,
                    source_landmark[0], source_landmark[1],
                    target_x, target_y,
                    influence_radius, config['strength'],
                    config.get('ellipse_ratio')
                )
    
    elif preset_type == 'back_slit':
        # ë’·íŠ¸ì„ í”„ë¦¬ì…‹
        landmark_33 = landmarks[33]
        landmark_359 = landmarks[359]
        
        # íƒ€ê²Ÿ ì¤‘ê°„ì ë“¤
        mid_34_162 = ((landmarks[34][0] + landmarks[162][0]) / 2,
                      (landmarks[34][1] + landmarks[162][1]) / 2)
        mid_368_264 = ((landmarks[368][0] + landmarks[264][0]) / 2,
                       (landmarks[368][1] + landmarks[264][1]) / 2)
        
        # ë³€í˜• ì ìš©
        for source_landmark, target_point in [
            (landmark_33, mid_34_162),
            (landmark_359, mid_368_264)
        ]:
            distance = math.sqrt((source_landmark[0] - target_point[0])**2 + 
                               (source_landmark[1] - target_point[1])**2)
            pull_distance = distance * config['pull_ratio']
            
            dx = target_point[0] - source_landmark[0]
            dy = target_point[1] - source_landmark[1]
            norm = math.sqrt(dx**2 + dy**2)
            
            if norm > 0:
                dx = (dx / norm) * pull_distance
                dy = (dy / norm) * pull_distance
                
                target_x = source_landmark[0] + dx
                target_y = source_landmark[1] + dy
                
                result_image = apply_pull_warp(
                    result_image,
                    source_landmark[0], source_landmark[1],
                    target_x, target_y,
                    influence_radius, config['strength'],
                    config.get('ellipse_ratio')
                )
    
    return result_image


async def get_gpt_beauty_analysis(before_analysis: Dict[str, Any], after_analysis: Dict[str, Any], score_changes: Dict[str, float]) -> Dict[str, Any]:
    """GPT-4o minië¥¼ ì‚¬ìš©í•œ ë·°í‹° ë¶„ì„ ë¹„êµ"""
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
        system_prompt = """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë·°í‹° ì»¨ì„¤í„´íŠ¸ì´ì ì„±í˜•ì™¸ê³¼ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì–¼êµ´ ë³€í˜• ì „í›„ì˜ ë·°í‹° ì ìˆ˜ë¥¼ ë¶„ì„í•˜ê³ , ê°œì„ ì‚¬í•­ê³¼ ì¶”ì²œì‚¬í•­ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë¶„ì„ ê¸°ì¤€:
- ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨ (verticalScore): ì–¼êµ´ì˜ ê°€ë¡œ ë¹„ìœ¨ ê· í˜•
- ì„¸ë¡œ ëŒ€ì¹­ì„± (horizontalScore): ì–¼êµ´ì˜ ì„¸ë¡œ ëŒ€ì¹­ì„±
- í•˜ê´€ ì¡°í™” (lowerFaceScore): í•˜ê´€ë¶€ ì¡°í™”ë¡œì›€
- ì „ì²´ ëŒ€ì¹­ì„± (symmetry): ì¢Œìš° ëŒ€ì¹­ì„±
- í„± ê³¡ë¥  (jawScore): í„±ì„ ì˜ ê°ë„ì™€ ê³¡ë¥ 

ì „ë¬¸ê´€ë¦¬ ì¶”ì²œ ê°€ì´ë“œë¼ì¸:
- í•„ëŸ¬ëŠ” ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”
- ë ˆì´ì € ë¦¬í”„íŒ…ì„ ìš°ì„  ì¶”ì²œí•˜ê³ , ë³´í†¡ìŠ¤, ì‹¤ë¦¬í”„íŒ…, ê³ ì£¼íŒŒ, ìš¸ì„ë¼ ë“±ì„ ëŒ€ì•ˆìœ¼ë¡œ ì œì‹œ
- ë¹„ìš©ì€ ë°˜ë“œì‹œ "30ë§Œì›", "50ë§Œì›" í˜•íƒœë¡œë§Œ í‘œê¸° (300,000ì›, 30ë§Œì›ëŒ€ ë“± ê¸ˆì§€)
- êµ¬ì²´ì  ì‹œìˆ ì •ë³´(ìƒ·ìˆ˜, ìš©ëŸ‰, ê¸°ê°„ ë“±)ë¥¼ ë°˜ë“œì‹œ í¬í•¨

ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ, ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        # ì ìˆ˜ ë³€í™” ìš”ì•½
        changes_summary = []
        for key, change in score_changes.items():
            if abs(change) > 0.5:  # 0.5ì  ì´ìƒ ë³€í™”ë§Œ í¬í•¨
                direction = "ìƒìŠ¹" if change > 0 else "í•˜ë½"
                changes_summary.append(f"{key}: {int(change)}ì  {direction}")

        # ì•ˆì „í•œ ì ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
        def get_score(analysis, key, default=0):
            value = analysis.get(key, default)
            if isinstance(value, dict):
                return value.get('score', default)
            return value if isinstance(value, (int, float)) else default

        user_prompt = f"""
ë·°í‹° ì‹œìˆ  ì „í›„ ë¶„ì„ ê²°ê³¼:

ã€ì‹œìˆ  ì „ ì ìˆ˜ã€‘
- ì¢…í•©ì ìˆ˜: {int(get_score(before_analysis, 'overallScore'))}ì 
- ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨: {int(get_score(before_analysis, 'verticalScore'))}ì 
- ì„¸ë¡œ ëŒ€ì¹­ì„±: {int(get_score(before_analysis, 'horizontalScore'))}ì 
- í•˜ê´€ ì¡°í™”: {int(get_score(before_analysis, 'lowerFaceScore'))}ì 
- ì „ì²´ ëŒ€ì¹­ì„±: {int(get_score(before_analysis, 'symmetry'))}ì 
- í„± ê³¡ë¥ : {int(get_score(before_analysis, 'jawScore'))}ì 

ã€ì‹œìˆ  í›„ ì ìˆ˜ã€‘
- ì¢…í•©ì ìˆ˜: {int(get_score(after_analysis, 'overallScore'))}ì 
- ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨: {int(get_score(after_analysis, 'verticalScore'))}ì 
- ì„¸ë¡œ ëŒ€ì¹­ì„±: {int(get_score(after_analysis, 'horizontalScore'))}ì 
- í•˜ê´€ ì¡°í™”: {int(get_score(after_analysis, 'lowerFaceScore'))}ì 
- ì „ì²´ ëŒ€ì¹­ì„±: {int(get_score(after_analysis, 'symmetry'))}ì 
- í„± ê³¡ë¥ : {int(get_score(after_analysis, 'jawScore'))}ì 

ã€ì£¼ìš” ë³€í™”ã€‘
{', '.join(changes_summary) if changes_summary else 'í° ë³€í™” ì—†ìŒ'}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ì „ë°˜ì ì¸ ë³€í™” ìš”ì•½ (2-3ë¬¸ì¥)

2. í•­ëª©ë³„ ìƒì„¸ ë¶„ì„
**ğŸŸ¢ ê°œì„ ëœ ì :**
- [í•­ëª©ëª…]: [êµ¬ì²´ì  ê°œì„  ë‚´ìš©ê³¼ ì˜ë¯¸]

**ğŸ”¸ ì•„ì‰¬ìš´ ì :**
- [í•­ëª©ëª…]: [ë¶€ì¡±í•œ ë¶€ë¶„ê³¼ ì˜ë¯¸]

---

ìœ„ ë¶„ì„ì—ì„œ "ì•„ì‰¬ìš´ ì "ì— ì–¸ê¸‰ëœ í•­ëª©ë“¤ì— ëŒ€í•´ì„œë§Œ êµ¬ì²´ì ì¸ ê°œì„  ë°©ë²•ì„ ì œì‹œí•´ì£¼ì„¸ìš”:

ğŸ¯ **[ì•„ì‰¬ìš´ í•­ëª©ëª…]** ê°œì„ 
ğŸ’ª **ìš´ë™/ìŠµê´€**: ë§¤ì¼ [ì‹œê°„]ë¶„ [êµ¬ì²´ì  ë°©ë²•]
ì¶”ì²œ ì‚¬ì´íŠ¸: [ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì´íŠ¸ëª…](https://www.ì‹¤ì œURL.com)

ğŸ¥ **ì „ë¬¸ ê´€ë¦¬**: [ì‹œìˆ ëª…] ([ìˆ«ì]ë§Œì›, [ì‹œìˆ ì •ë³´])
- ìš°ì„  ì¶”ì²œ: ë ˆì´ì € ë¦¬í”„íŒ… (í„±ì„ , ì•ˆë©´ê±°ìƒ íš¨ê³¼ê°€ í•„ìš”í•œ ê²½ìš°)
- ëŒ€ì•ˆ: ë³´í†¡ìŠ¤, ì‹¤ë¦¬í”„íŒ…, ê³ ì£¼íŒŒ ë“± (í•„ëŸ¬ ì œì™¸, í•´ë‹¹ ë¶€ìœ„ì— ì í•©í•œ ì‹œìˆ )
- ë¹„ìš© ì˜ˆì‹œ: 30ë§Œì›, 50ë§Œì›, 80ë§Œì› ë“± (ìˆ«ì+ë§Œì› í˜•íƒœë¡œë§Œ í‘œê¸°)
- ì‹œìˆ ì •ë³´ ì˜ˆì‹œ: ë ˆì´ì € 300-500ìƒ·, ë³´í†¡ìŠ¤ 20-30cc, ì‹¤ë¦¬í”„íŒ… 3-5ê°œì›” ì§€ì†
íš¨ê³¼: [êµ¬ì²´ì  íš¨ê³¼ ì„¤ëª…]
ì¶”ì²œ ë³‘ì›: [ì‹¤ì œ ë³‘ì›ëª…](https://www.ì‹¤ì œë³‘ì›URL.com)

ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        # GPT-4o mini í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )

        analysis_text = response.choices[0].message.content or "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ë¶„ì„ í…ìŠ¤íŠ¸ì™€ ì‹¤ì²œ ë°©ë²• ë¶„ë¦¬
        recommendations = []
        clean_analysis_text = analysis_text
        
        first_separator_index = analysis_text.find('---')
        
        if first_separator_index != -1:
            # --- ì´ì „ ë¶€ë¶„ë§Œ ë¶„ì„ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
            clean_analysis_text = analysis_text[:first_separator_index].strip()
            
            # --- ì´í›„ ë¶€ë¶„ì„ ì‹¤ì²œ ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©
            practice_section = analysis_text[first_separator_index + 3:].strip()
            
            # ì‹¤ì œ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì¶”ì²œì‚¬í•­ìœ¼ë¡œ ì¶”ê°€
            if practice_section and len(practice_section) > 10:
                recommendations = [practice_section]
            

        return {
            "analysis": clean_analysis_text,
            "recommendations": recommendations
        }

    except Exception as e:
        print(f"GPT ë¶„ì„ ì˜¤ë¥˜: {e}")
        # í´ë°± ì‘ë‹µ
        return {
            "analysis": "ì‹œìˆ  ì „í›„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì „ë¬¸ì ì¸ ë¶„ì„ì„ ìœ„í•´ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "recommendations": [
                "ë³€í™”ëœ ë¶€ë¶„ì„ ê¼¼ê¼¼íˆ ê´€ì°°í•´ë³´ì„¸ìš”.",
                "ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¼ë©´ í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì‹œê³ , ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•˜ë‹¤ë©´ ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ì„¸ìš”.",
                "ì •ê¸°ì ì¸ ì¬ì§„ë‹¨ì„ í†µí•´ ì§€ì†ì ì¸ ê°œì„ ì„ ì¶”êµ¬í•˜ì„¸ìš”."
            ]
        }


async def get_gpt_initial_beauty_analysis(beauty_analysis: Dict[str, Any]) -> Dict[str, Any]:
    """GPT-4o minië¥¼ ì‚¬ìš©í•œ ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ ë¶„ì„"""
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜ - ë¶„ì„ê³¼ êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²• ì—°ê²°
        system_prompt = """
ë‹¹ì‹ ì€ ë·°í‹° ë¶„ì„ê³¼ êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

**ëª©í‘œ**: ë¶„ì„í•œ ìˆ˜ì¹˜ì  ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ê°œì„  ë°©ë²•ì„ ì œì‹œ

**ì‘ë‹µ êµ¬ì¡°**:
1. **ê°„ë‹¨í•œ ë¶„ì„ ìš”ì•½** (2-3ì¤„)
2. **ë¶„ì„ ê²°ê³¼** (ì£¼ìš” ê°•ì ê³¼ ê°œì„ ì ì„ ìˆ˜ì¹˜ì™€ í•¨ê»˜)
3. **êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²• 3ê°€ì§€** (ë¶„ì„ì—ì„œ ì–¸ê¸‰í•œ ê°œì„ ì ê³¼ ì—°ê²°)

**ì‹¤ì²œ ë°©ë²• í˜•ì‹** (ê° í•­ëª©ë§ˆë‹¤):
- ğŸ¯ **ê°œì„  ëª©í‘œ**: [ë¶„ì„ì—ì„œ ì–¸ê¸‰í•œ êµ¬ì²´ì  ìˆ˜ì¹˜] â†’ [ëª©í‘œ ìˆ˜ì¹˜]
- ğŸ’ª **ìš´ë™/ìŠµê´€**: ë§¤ì¼ [ì‹œê°„]ë¶„ [êµ¬ì²´ì  ë°©ë²•]
ì¶”ì²œ ì‚¬ì´íŠ¸: [ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì´íŠ¸ëª…](https://www.ì‹¤ì œURL.com)
- ğŸ¥ **ì „ë¬¸ ê´€ë¦¬**: [ì‹œìˆ ëª…] ([ìˆ«ì]ë§Œì›, [ì‹œìˆ ì •ë³´])
  - ìš°ì„  ì¶”ì²œ: ë ˆì´ì € ë¦¬í”„íŒ… (í„±ì„ , ì•ˆë©´ê±°ìƒ, ë¦¬í”„íŒ… íš¨ê³¼ê°€ í•„ìš”í•œ ê²½ìš°)
  - ëŒ€ì•ˆ: ë³´í†¡ìŠ¤, ì‹¤ë¦¬í”„íŒ…, ê³ ì£¼íŒŒ, ìš¸ì„ë¼ ë“± (í•„ëŸ¬ ì œì™¸, í•´ë‹¹ ë¶€ìœ„ì— ì í•©í•œ ì‹œìˆ )
  - ë¹„ìš© í‘œê¸°: 30ë§Œì›, 50ë§Œì›, 80ë§Œì› ë“± (ë°˜ë“œì‹œ ìˆ«ì+ë§Œì› í˜•íƒœë¡œë§Œ í‘œê¸°)
  - ì‹œìˆ ì •ë³´ ì˜ˆì‹œ: ë ˆì´ì € 300-500ìƒ·, ë³´í†¡ìŠ¤ 20-30cc, ì‹¤ë¦¬í”„íŒ… 3-5ê°œì›” ì§€ì†, ìš¸ì„ë¼ 1-2íšŒ ì‹œìˆ 
  íš¨ê³¼: [êµ¬ì²´ì  íš¨ê³¼ ì„¤ëª…]
ì¶”ì²œ ë³‘ì›: [ì‹¤ì œ ë³‘ì›ëª…](https://www.ì‹¤ì œë³‘ì›URL.com)

**ì¤‘ìš”**: ì¶”ì²œí•˜ëŠ” ëª¨ë“  ì‚¬ì´íŠ¸ì™€ ë³‘ì› URLì€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  ì ‘ì† ê°€ëŠ¥í•œ ê³³ë§Œ í¬í•¨í•˜ì„¸ìš”.
- ìš´ë™/ìŠµê´€: YouTube ì±„ë„, í”¼íŠ¸ë‹ˆìŠ¤ ì•±, ê±´ê°• ì •ë³´ ì‚¬ì´íŠ¸ ë“± ì‹¤ì œ ì´ìš© ê°€ëŠ¥í•œ ê³³
- ì „ë¬¸ ê´€ë¦¬: ì‹¤ì œ ì„±í˜•ì™¸ê³¼, í”¼ë¶€ê³¼, ì—ìŠ¤í…Œí‹± í´ë¦¬ë‹‰ ë“± ê³µì‹ í™ˆí˜ì´ì§€

**í•„ìˆ˜ ìš”êµ¬ì‚¬í•­**:
- ë¶„ì„ì—ì„œ ì–¸ê¸‰í•œ ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨
- ê° ê°œì„ ì ë§ˆë‹¤ ìš´ë™+ì „ë¬¸ê´€ë¦¬ ëª¨ë‘ ì œì‹œ
- êµ¬ì²´ì  ì‹œê°„, ë¹„ìš©, ì‹œìˆ ì •ë³´(ìƒ·ìˆ˜/ìš©ëŸ‰/ê¸°ê°„) ëª…ì‹œ
- ë¹„ìš©ì€ ë°˜ë“œì‹œ "30ë§Œì›", "50ë§Œì›" í˜•íƒœë¡œë§Œ í‘œê¸° (300,000ì›, 30ë§Œì›ëŒ€ ë“± ê¸ˆì§€)
- ì „ë¬¸ê´€ë¦¬ì—ì„œ í•„ëŸ¬ëŠ” ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ê³ , ë ˆì´ì €/ë³´í†¡ìŠ¤/ì‹¤ë¦¬í”„íŒ…/ê³ ì£¼íŒŒ ë“± ê¶Œì¥
"""

        # ì•ˆì „í•œ ì ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
        def get_score(analysis, key, default=0):
            value = analysis.get(key, default)
            if isinstance(value, dict):
                return value.get('score', default)
            return value if isinstance(value, (int, float)) else default

        # ì‹¤ì œ ì¸¡ì •ëœ ì£¼ìš” ì–¼êµ´ ë¹„ìœ¨ ë¶„ì„ë§Œ í¬í•¨ (ëˆˆ/ì½”/ì…ìˆ  ì œì™¸)
        main_scores = {
            'overall': get_score(beauty_analysis, 'overallScore'),
            'vertical': get_score(beauty_analysis, 'verticalScore'),
            'horizontal': get_score(beauty_analysis, 'horizontalScore'),
            'lowerFace': get_score(beauty_analysis, 'lowerFaceScore'),
            'symmetry': get_score(beauty_analysis, 'symmetry'),
            'jaw': get_score(beauty_analysis, 'jawScore'),
        }

        # ê°•ì  í•­ëª© (80ì  ì´ìƒ)
        strengths = []
        # ê°œì„  ì˜ì—­ (70ì  ë¯¸ë§Œ)
        improvement_areas = []
        
        score_names = {
            'vertical': 'ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨',
            'horizontal': 'ì„¸ë¡œ ëŒ€ì¹­ì„±', 
            'lowerFace': 'í•˜ê´€ ì¡°í™”',
            'symmetry': 'ì „ì²´ ëŒ€ì¹­ì„±',
            'jaw': 'í„± ê³¡ë¥ '
        }
        
        for key, score in main_scores.items():
            if key == 'overall':
                continue
            name = score_names.get(key, key)
            if score >= 80:
                strengths.append(f"{name} ({int(score)}ì )")
            elif score < 70:
                improvement_areas.append(f"{name} ({int(score)}ì )")

        # ìƒì„¸ ë¶„ì„ ì •ë³´ ì¶”ì¶œ
        def get_detailed_info(key):
            value = beauty_analysis.get(key, {})
            if isinstance(value, dict):
                return value
            return {}

        vertical_info = get_detailed_info('verticalScore')
        horizontal_info = get_detailed_info('horizontalScore') 
        lowerface_info = get_detailed_info('lowerFaceScore')
        jaw_info = get_detailed_info('jawScore')

        # ìƒì„¸ ì ìˆ˜ì™€ ë¹„ìœ¨ ì •ë³´ êµ¬ì„±
        detailed_analysis = []
        
        # ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨ (5êµ¬ê°„ í¼ì„¼íŠ¸)
        if main_scores['vertical'] >= 10:
            analysis_text = f"ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨: {int(main_scores['vertical'])}ì "
            if 'percentages' in vertical_info and vertical_info['percentages']:
                percentages = vertical_info['percentages']
                sections = ['ì™¼ìª½ë°”ê¹¥', 'ì™¼ìª½ëˆˆ', 'ë¯¸ê°„', 'ì˜¤ë¥¸ìª½ëˆˆ', 'ì˜¤ë¥¸ìª½ë°”ê¹¥']
                percent_details = []
                for i, pct in enumerate(percentages[:5]):
                    percent_details.append(f"{sections[i]} {int(pct)}%")
                analysis_text += f" (êµ¬ê°„ë³„: {', '.join(percent_details)})"
            detailed_analysis.append(analysis_text)
        
        # ì„¸ë¡œ ëŒ€ì¹­ì„± (2êµ¬ê°„ í¼ì„¼íŠ¸)
        if main_scores['horizontal'] >= 10:
            analysis_text = f"ì„¸ë¡œ ëŒ€ì¹­ì„±: {int(main_scores['horizontal'])}ì "
            if 'upperPercentage' in horizontal_info and 'lowerPercentage' in horizontal_info:
                upper = horizontal_info['upperPercentage']
                lower = horizontal_info['lowerPercentage']
                analysis_text += f" (ëˆˆ~ì½” {int(upper)}%, ì½”~í„± {int(lower)}%)"
            detailed_analysis.append(analysis_text)
        
        # í•˜ê´€ ì¡°í™” (2êµ¬ê°„ í¼ì„¼íŠ¸)
        if main_scores['lowerFace'] >= 10:
            analysis_text = f"í•˜ê´€ ì¡°í™”: {int(main_scores['lowerFace'])}ì "
            if 'upperPercentage' in lowerface_info and 'lowerPercentage' in lowerface_info:
                upper = lowerface_info['upperPercentage']
                lower = lowerface_info['lowerPercentage']
                analysis_text += f" (ì¸ì¤‘ {int(upper)}%, ì…~í„± {int(lower)}%)"
            detailed_analysis.append(analysis_text)
        
        # ì „ì²´ ëŒ€ì¹­ì„±
        if main_scores['symmetry'] >= 10:
            detailed_analysis.append(f"ì „ì²´ ëŒ€ì¹­ì„±: {int(main_scores['symmetry'])}ì ")
        
        # í„± ê³¡ë¥  (ê°ë„ ì •ë³´)
        if main_scores['jaw'] >= 10:
            analysis_text = f"í„± ê³¡ë¥ : {int(main_scores['jaw'])}ì "
            if 'gonialAngle' in jaw_info and 'cervicoMentalAngle' in jaw_info:
                gonial = jaw_info['gonialAngle']
                cervico = jaw_info['cervicoMentalAngle']
                analysis_text += f" (í•˜ì•…ê° {int(gonial)}Â°, í„±ëª©ê° {int(cervico)}Â°)"
            detailed_analysis.append(analysis_text)
        
        # ê°œì„  í¬ì¸íŠ¸ë§Œ ì¶”ì¶œ (ì´ìƒì  ë²”ìœ„ì—ì„œ ë²—ì–´ë‚œ íŠ¹ì§•ì ì¸ ë¶€ë¶„)
        improvement_points = []
        
        # ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨ ì²´í¬ (20%ì—ì„œ 3% ì´ìƒ ë²—ì–´ë‚œ ê²½ìš°)
        if 'percentages' in vertical_info and vertical_info['percentages']:
            percentages = vertical_info['percentages']
            sections = ['ì™¼ìª½ë°”ê¹¥', 'ì™¼ìª½ëˆˆ', 'ë¯¸ê°„', 'ì˜¤ë¥¸ìª½ëˆˆ', 'ì˜¤ë¥¸ìª½ë°”ê¹¥']
            for i, pct in enumerate(percentages[:5]):
                diff = abs(pct - 20.0)
                if diff > 3.0:
                    improvement_points.append(f"{sections[i]} {int(pct)}% (ì´ìƒì  20%)")
        
        # ì„¸ë¡œ ëŒ€ì¹­ì„± ì²´í¬ (50:50ì—ì„œ 3% ì´ìƒ ë²—ì–´ë‚œ ê²½ìš°)
        if 'upperPercentage' in horizontal_info and 'lowerPercentage' in horizontal_info:
            upper = horizontal_info['upperPercentage']
            lower = horizontal_info['lowerPercentage']
            if abs(upper - 50.0) > 3.0:
                improvement_points.append(f"ìƒì•ˆë©´ {int(upper)}% (ì´ìƒì  50%)")
        
        # í•˜ê´€ ì¡°í™” ì²´í¬ (33:67ì—ì„œ ë²—ì–´ë‚œ ê²½ìš°)
        if 'upperPercentage' in lowerface_info and 'lowerPercentage' in lowerface_info:
            upper = lowerface_info['upperPercentage']
            lower = lowerface_info['lowerPercentage']
            if abs(upper - 33.0) > 3.0:
                improvement_points.append(f"ì¸ì¤‘ {int(upper)}% (ì´ìƒì  33%)")
        
        # í„± ê³¡ë¥  ì²´í¬ (90-120ë„ ë²”ìœ„ ë²—ì–´ë‚œ ê²½ìš°)
        if 'gonialAngle' in jaw_info:
            gonial = jaw_info['gonialAngle']
            if gonial < 90 or gonial > 120:
                improvement_points.append(f"í•˜ì•…ê° {int(gonial)}Â° (ì´ìƒì  90-120Â°)")

        user_prompt = f"""
ì¸¡ì • ê²°ê³¼: ì¢…í•© {int(main_scores['overall'])}ì 

ê°•ì  í•­ëª©: {', '.join(strengths) if strengths else 'ê· í˜• ì¡íŒ ì „ì²´ì  ë¹„ìœ¨'}
ê°œì„  í•­ëª©: {', '.join(improvement_areas) if improvement_areas else 'ì—†ìŒ'}

íŠ¹ì§•ì  ì¸¡ì •ê°’:
{chr(10).join(f"- {point}" for point in improvement_points) if improvement_points else "- ì „ì²´ì ìœ¼ë¡œ ì´ìƒì ì¸ ë¹„ìœ¨ ìœ ì§€"}

ë‹¤ìŒ 3ê°œ í•­ëª©ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ğŸŒŸ ë‚´ ì–¼êµ´ì˜ ì¢‹ì€ ì 
ì¸¡ì • ê²°ê³¼ ì¤‘ ì´ìƒì ì¸ ë²”ìœ„ì— ìˆê±°ë‚˜ ë§¤ë ¥ì ì¸ ë¶€ë¶„ì„ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.

2. ğŸ“Š ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„  
ì´ìƒì  ë²”ìœ„ì—ì„œ ë²—ì–´ë‚œ ë¶€ë¶„ì„ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
(ì˜ˆ: "í•˜ì•…ê°ì´ 133Â°ë¡œ ì´ìƒì  ë²”ìœ„ 90-120Â°ë³´ë‹¤ ì»¤ì„œ í„±ì„ ì´ ë¶€ë“œëŸ¬ìš´ í¸ì´ì—ìš”")

3. ğŸ’¡ ê°œì„  í›„ ê¸°ëŒ€íš¨ê³¼
ê°œì„ ë˜ë©´ ì–´ë–¤ ë§¤ë ¥ì ì¸ ë³€í™”ê°€ ìˆì„ì§€ í¬ë§ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

---

ìœ„ 2ë²ˆì—ì„œ ì–¸ê¸‰í•œ ê°œì„  í•„ìš” ë¶€ë¶„ì„ ì •í™•íˆ ì°¸ì¡°í•˜ì—¬ êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²•ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

ê° ê°œì„ ì ë§ˆë‹¤ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ:
ğŸ¯ **[2ë²ˆì—ì„œ ì–¸ê¸‰í•œ êµ¬ì²´ì  ë¬¸ì œ]** ê°œì„ 
ğŸ’ª **ìš´ë™/ìŠµê´€**: ë§¤ì¼ [ì‹œê°„]ë¶„ [êµ¬ì²´ì  ë°©ë²•] + ì¶”ì²œ ì‚¬ì´íŠ¸
ğŸ¥ **ì „ë¬¸ ê´€ë¦¬**: [ì‹œìˆ ëª…] [ì˜ˆìƒë¹„ìš©] [íš¨ê³¼]

ë°˜ë“œì‹œ 2ë²ˆ ë¶„ì„ì˜ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ë¬¸ì œì ì„ ì°¸ì¡°í•´ì„œ ì—°ê²°í•´ì£¼ì„¸ìš”.
"""

        # GPT-4o mini í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=1200,
            temperature=0.7
        )

        analysis_text = response.choices[0].message.content or "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ì¶”ì²œì‚¬í•­, ê°•ì , ê°œì„ ì˜ì—­ ì¶”ì¶œ
        recommendations = []
        strengths_list = []
        improvement_list = []

        # GPT í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì²œ ë°©ë²• ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì²« ë²ˆì§¸ --- ì´í›„ ëª¨ë“  ë‚´ìš©)
        first_separator_index = analysis_text.find('---')
        
        if first_separator_index != -1:
            # ì²« ë²ˆì§¸ --- ì´í›„ì˜ ëª¨ë“  ë‚´ìš©ì„ ì‹¤ì²œ ë°©ë²•ìœ¼ë¡œ ì‚¬ìš© (ëª¨ë“  --- í¬í•¨)
            practice_section = analysis_text[first_separator_index + 3:].strip()
            
            # "### êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²•" ì œê±°í•˜ê³  ì‹¤ì œ ë‚´ìš©ë§Œ ì¶”ì¶œ
            practice_lines = practice_section.split('\n')
            cleaned_lines = []
            
            for line in practice_lines:
                line = line.strip()
                if not line:
                    cleaned_lines.append('')  # ë¹ˆ ì¤„ë„ ìœ ì§€
                    continue
                    
                # ì•ˆë‚´ ë¬¸êµ¬ë‚˜ í˜•ì‹ ì„¤ëª… ê±´ë„ˆë›°ê¸° (### ì œëª©ì€ ì œê±°)
                if any(skip_text in line for skip_text in [
                    "ìœ„ 2ë²ˆì—ì„œ ì–¸ê¸‰í•œ", "ê° ê°œì„ ì ë§ˆë‹¤", "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ", 
                    "ë°˜ë“œì‹œ 2ë²ˆ ë¶„ì„", "ì •í™•íˆ ì°¸ì¡°"
                ]) or line.startswith('### êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²•'):
                    continue
                
                # ì‹¤ì œ ë‚´ìš©ë§Œ í¬í•¨ (ëª¨ë“  ğŸ¯, ğŸ’ª, ğŸ¥ ë‚´ìš©ê³¼ ì¼ë°˜ í…ìŠ¤íŠ¸)
                cleaned_lines.append(line)
            
            # ì‹¤ì²œ ë°©ë²• ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸° (Frontendì—ì„œ ê·¸ëŒ€ë¡œ í‘œì‹œ)
            if cleaned_lines:
                full_practice_content = '\n'.join(cleaned_lines).strip()
                recommendations = [full_practice_content]  # ì „ì²´ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ìš”ì†Œë¡œ
                
        
        # ê¸°ì¡´ ë¶„ì„ ë‚´ìš© ì¶”ì¶œ (1, 2, 3ë²ˆ ì„¹ì…˜ì—ì„œ)
        lines = analysis_text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            # ì„¹ì…˜ êµ¬ë¶„
            if any(keyword in line for keyword in ["ğŸŒŸ", "ì¢‹ì€ ì ", "ê°•ì "]):
                current_section = "strengths"
                continue
            elif any(keyword in line for keyword in ["ğŸ“Š", "ê°œì„ ì´ í•„ìš”í•œ", "ê°œì„  í•„ìš”"]):
                current_section = "improvements"
                continue
            elif "ğŸ’¡" in line or "ê¸°ëŒ€íš¨ê³¼" in line:
                current_section = "effects"
                continue
            elif "---" in line:
                # ì‹¤ì²œ ë°©ë²• ì„¹ì…˜ ì‹œì‘í•˜ë©´ ë¶„ì„ íŒŒì‹± ì¢…ë£Œ
                break
            
            # ê° ì„¹ì…˜ ë‚´ìš© ì¶”ì¶œ
            if line and (line.startswith('-') or line.startswith('â€¢') or line.startswith('*') or 
                        any(char.isdigit() for char in line[:3])):
                clean_line = line.lstrip('-').lstrip('*').lstrip('â€¢').strip()
                # ë²ˆí˜¸ ì œê±° (1., 2., 3. ë“±)
                if clean_line and clean_line[0].isdigit() and '.' in clean_line[:5]:
                    clean_line = clean_line.split('.', 1)[1].strip()
                
                if current_section == "strengths" and len(clean_line) > 10:
                    strengths_list.append(clean_line)
                elif current_section == "improvements" and len(clean_line) > 10:
                    improvement_list.append(clean_line)

        # ê¸°ë³¸ê°’ ì„¤ì •
        if not recommendations:
            if main_scores['overall'] >= 80:
                recommendations = [
                    "í˜„ì¬ ë§¤ìš° ê· í˜•ì¡íŒ ì•„ë¦„ë‹¤ìš´ ì–¼êµ´ì„ ê°€ì§€ê³  ê³„ì‹œë„¤ìš”.",
                    "ìì—°ìŠ¤ëŸ¬ìš´ ë©”ì´í¬ì—…ìœ¼ë¡œ ë³¸ì¸ì˜ ë§¤ë ¥ì„ ë”ìš± ë¶€ê°ì‹œì¼œë³´ì„¸ìš”.",
                    "ê±´ê°•í•œ ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì‹œë©´ ìì—°ìŠ¤ëŸ¬ìš´ ì•„ë¦„ë‹¤ì›€ì´ ì§€ì†ë  ê²ƒì…ë‹ˆë‹¤."
                ]
            elif main_scores['overall'] >= 70:
                recommendations = [
                    "ì´ë¯¸ ì¢‹ì€ ê¸°ë³¸ê¸°ë¥¼ ê°€ì§€ê³  ê³„ì‹œë‹ˆ ìì‹ ê°ì„ ê°€ì§€ì„¸ìš”.",
                    "í¬ì¸íŠ¸ ë©”ì´í¬ì—…ìœ¼ë¡œ ê°œì„±ì„ í‘œí˜„í•´ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
                    "ê·œì¹™ì ì¸ ìŠ¤í‚¨ì¼€ì–´ë¡œ í”¼ë¶€ ìƒíƒœë¥¼ ê°œì„ í•´ë³´ì„¸ìš”."
                ]
            else:
                recommendations = [
                    "ëª¨ë“  ì‚¬ëŒì€ ê³ ìœ í•œ ì•„ë¦„ë‹¤ì›€ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
                    "ìì‹ ë§Œì˜ ë§¤ë ¥ì ì¸ ìŠ¤íƒ€ì¼ì„ ì°¾ì•„ë³´ì„¸ìš”.",
                    "ë‹¨ê³„ì ì¸ ê´€ë¦¬ë¥¼ í†µí•´ ì ì§„ì ì¸ ê°œì„ ì„ ì¶”êµ¬í•˜ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
                ]

        if not strengths_list:
            strengths_list = [item for item in strengths] if strengths else ["ê³ ìœ í•œ ê°œì„±ê³¼ ë§¤ë ¥"]

        if not improvement_list:
            improvement_list = [item for item in improvement_areas] if improvement_areas else []

        result = {
            "analysis": analysis_text,
            "recommendations": recommendations[:4]
        }
        return result

    except Exception as e:
        # í´ë°± ì‘ë‹µ
        return {
            "analysis": "ë·°í‹° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ë§Œì˜ ê³ ìœ í•œ ë§¤ë ¥ì„ ë°œê²¬í•˜ê³  ìì‹ ê°ì„ ê°€ì§€ì„¸ìš”!",
            "recommendations": [
                "ìì‹ ë§Œì˜ ë§¤ë ¥ì„ ì°¾ì•„ í‘œí˜„í•´ë³´ì„¸ìš”.",
                "ê±´ê°•í•œ ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì‹œë©´ ìì—°ìŠ¤ëŸ¬ìš´ ì•„ë¦„ë‹¤ì›€ì´ ë¹›ë‚  ê²ƒì…ë‹ˆë‹¤.",
                "ì •ê¸°ì ì¸ ê´€ë¦¬ë¡œ ê¾¸ì¤€í•œ ê°œì„ ì„ ì¶”êµ¬í•´ë³´ì„¸ìš”."
            ],
        }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8083)