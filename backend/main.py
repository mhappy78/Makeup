from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Tuple, Dict, Any
import io
import cv2
import numpy as np
from PIL import Image
import mediapipe as mp
import base64
import uuid
import os
import math
from datetime import datetime
import openai
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai.api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Face Simulator API",
    description="ì–¼êµ´ ì„±í˜• ì‹œë®¬ë ˆì´í„° ë°±ì—”ë“œ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Flutter ì›¹/ì•±ì—ì„œ ì ‘ê·¼ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MediaPipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# ì „ì—­ ë³€ìˆ˜
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=True,
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5
)

# ì„ì‹œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
TEMP_DIR = "temp_images"
os.makedirs(TEMP_DIR, exist_ok=True)

# Pydantic ëª¨ë¸ë“¤
class WarpRequest(BaseModel):
    image_id: str
    start_x: float
    start_y: float
    end_x: float
    end_y: float
    influence_radius: float = 80.0
    strength: float = 1.0
    mode: str = "pull"  # pull, push, expand, shrink

class PresetRequest(BaseModel):
    image_id: str
    preset_type: str  # lower_jaw, middle_jaw, cheek, front_protusion, back_slit

class LandmarkResponse(BaseModel):
    landmarks: List[Tuple[float, float]]
    image_width: int
    image_height: int

class ImageResponse(BaseModel):
    image_id: str
    image_data: str  # base64 encoded

class BeautyComparisonRequest(BaseModel):
    before_analysis: Dict[str, Any]  # ì´ì „ ë·°í‹° ë¶„ì„ ê²°ê³¼
    after_analysis: Dict[str, Any]   # í˜„ì¬ ë·°í‹° ë¶„ì„ ê²°ê³¼

class BeautyComparisonResponse(BaseModel):
    overall_change: str  # ì „ë°˜ì  ë³€í™” ("improved", "declined", "similar")
    score_changes: Dict[str, float]  # ê° í•­ëª©ë³„ ì ìˆ˜ ë³€í™”
    recommendations: List[str]  # GPT ì¶”ì²œì‚¬í•­
    analysis_text: str  # ìƒì„¸ ë¶„ì„ í…ìŠ¤íŠ¸

class InitialBeautyAnalysisRequest(BaseModel):
    beauty_analysis: Dict[str, Any]  # ë·°í‹° ë¶„ì„ ê²°ê³¼

class InitialBeautyAnalysisResponse(BaseModel):
    analysis_text: str  # ìƒì„¸ ë¶„ì„ í…ìŠ¤íŠ¸
    recommendations: List[str]  # GPT ì¶”ì²œì‚¬í•­
    strengths: List[str]  # ê°•ì  ë¶„ì„
    improvement_areas: List[str]  # ê°œì„  ì˜ì—­

    
@app.get("/")
async def root():
    return {"message": "Face Simulator API", "status": "running"}

@app.post("/upload-image")
async def upload_image(file: UploadFile = File(...)):
    """ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ID ë°˜í™˜"""
    try:
        # íŒŒì¼ ê²€ì¦
        if not file.content_type.startswith("image/"):
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ID ìƒì„±
        image_id = str(uuid.uuid4())
        
        # íŒŒì¼ ì½ê¸° ë° ì €ì¥
        contents = await file.read()
        
        # OpenCVë¡œ ì´ë¯¸ì§€ ì½ê¸°
        nparr = np.frombuffer(contents, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if image is None:
            raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ íŒŒì¼ì…ë‹ˆë‹¤")
        
        # RGBë¡œ ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        cv2.imwrite(temp_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))
        
        # ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
        height, width = image_rgb.shape[:2]
        
        return {
            "image_id": image_id,
            "width": width,
            "height": height,
            "message": "ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@app.get("/landmarks/{image_id}")
async def get_face_landmarks(image_id: str):
    """ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(temp_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        height, width = image_rgb.shape[:2]
        
        # MediaPipeë¡œ ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
        results = face_mesh.process(image_rgb)
        
        if not results.multi_face_landmarks:
            raise HTTPException(status_code=404, detail="ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ
        landmarks = []
        face_landmarks = results.multi_face_landmarks[0]
        
        for landmark in face_landmarks.landmark:
            x = landmark.x * width
            y = landmark.y * height
            landmarks.append((x, y))
        
        return LandmarkResponse(
            landmarks=landmarks,
            image_width=width,
            image_height=height
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e) or "ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"ëœë“œë§ˆí¬ ê²€ì¶œ ì‹¤íŒ¨: {str(e)}")

@app.post("/warp-image")
async def warp_image(request: WarpRequest):
    """ì´ë¯¸ì§€ ì›Œí•‘(ììœ ë³€í˜•) ì ìš©"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{request.image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(temp_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì›Œí•‘ ì ìš©
        warped_image = apply_warp(
            image_rgb,
            start_x=request.start_x,
            start_y=request.start_y,
            end_x=request.end_x,
            end_y=request.end_y,
            influence_radius=request.influence_radius,
            strength=request.strength,
            mode=request.mode
        )
        
        # ìƒˆë¡œìš´ UUIDë¡œ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ (ì›ë³¸ ë³´ì¡´)
        import uuid
        new_image_id = str(uuid.uuid4())
        new_temp_path = os.path.join(TEMP_DIR, f"{new_image_id}.jpg")
        cv2.imwrite(new_temp_path, cv2.cvtColor(warped_image, cv2.COLOR_RGB2BGR))
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜
        pil_image = Image.fromarray(warped_image)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='JPEG', quality=95)
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        return ImageResponse(
            image_id=new_image_id,
            image_data=img_base64
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì›Œí•‘ ì‹¤íŒ¨: {str(e)}")

@app.get("/download-image/{image_id}")
async def download_image(image_id: str):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        def iterfile(file_path: str):
            with open(file_path, mode="rb") as file_like:
                yield from file_like
        
        return StreamingResponse(
            iterfile(temp_path),
            media_type="image/jpeg",
            headers={"Content-Disposition": f"attachment; filename=face_simulator_result_{image_id[:8]}.jpg"}
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

@app.post("/apply-preset")
async def apply_preset(request: PresetRequest):
    """í”„ë¦¬ì…‹ ì ìš©"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{request.image_id}.jpg")
        
        if not os.path.exists(temp_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(temp_path)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
        results = face_mesh.process(image_rgb)
        
        if not results.multi_face_landmarks:
            raise HTTPException(status_code=404, detail="ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ì¶œ
        height, width = image_rgb.shape[:2]
        landmarks = []
        face_landmarks = results.multi_face_landmarks[0]
        
        for landmark in face_landmarks.landmark:
            x = landmark.x * width
            y = landmark.y * height
            landmarks.append((x, y))
        
        # í”„ë¦¬ì…‹ ì ìš©
        result_image = apply_preset_transformation(image_rgb, landmarks, request.preset_type)
        
        # ìƒˆë¡œìš´ UUIDë¡œ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        new_image_id = str(uuid.uuid4())
        new_temp_path = os.path.join(TEMP_DIR, f"{new_image_id}.jpg")
        cv2.imwrite(new_temp_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))
        
        # Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜
        pil_image = Image.fromarray(result_image)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='JPEG', quality=95)
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        return ImageResponse(
            image_id=new_image_id,
            image_data=img_base64
        )
        
    except Exception as e:
        if "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e) or "ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in str(e):
            raise e
        raise HTTPException(status_code=500, detail=f"í”„ë¦¬ì…‹ ì ìš© ì‹¤íŒ¨: {str(e)}")

@app.delete("/image/{image_id}")
async def delete_image(image_id: str):
    """ì„ì‹œ ì´ë¯¸ì§€ ì‚­ì œ"""
    try:
        temp_path = os.path.join(TEMP_DIR, f"{image_id}.jpg")
        
        if os.path.exists(temp_path):
            os.remove(temp_path)
            return {"message": "ì´ë¯¸ì§€ ì‚­ì œ ì„±ê³µ"}
        else:
            return {"message": "ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

@app.post("/analyze-beauty-comparison")
async def analyze_beauty_comparison(request: BeautyComparisonRequest):
    """ë·°í‹° ì ìˆ˜ ë³€í™” ë¶„ì„ ë° GPT ì¶”ì²œ"""
    try:
        before = request.before_analysis
        after = request.after_analysis
        
        # ì ìˆ˜ ë³€í™” ê³„ì‚°
        score_changes = {}
        if 'overallScore' in before and 'overallScore' in after:
            score_changes['overall'] = after['overallScore'] - before['overallScore']
        
        # ì„¸ë¶€ í•­ëª©ë³„ ë³€í™”
        detail_items = ['verticalScore', 'horizontalScore', 'lowerFaceScore', 'symmetry', 'eyeScore', 'noseScore', 'lipScore', 'jawScore']
        for item in detail_items:
            if item in before and item in after:
                # ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì¸ ê²½ìš° 'score' í‚¤ì—ì„œ ê°’ ì¶”ì¶œ
                if isinstance(before[item], dict) and isinstance(after[item], dict):
                    before_score = before[item].get('score', 0)
                    after_score = after[item].get('score', 0)
                    score_changes[item] = after_score - before_score
                else:
                    # ìˆ«ì íƒ€ì…ì¸ ê²½ìš° ì§ì ‘ ê³„ì‚°
                    score_changes[item] = after[item] - before[item]
        
        # ì „ë°˜ì  ë³€í™” íŒë‹¨
        overall_change = "similar"
        if score_changes.get('overall', 0) > 2:
            overall_change = "improved"
        elif score_changes.get('overall', 0) < -2:
            overall_change = "declined"
        
        # GPT-4o minië¥¼ ì‚¬ìš©í•œ ë¶„ì„
        analysis_result = await get_gpt_beauty_analysis(before, after, score_changes)
        
        return BeautyComparisonResponse(
            overall_change=overall_change,
            score_changes=score_changes,
            recommendations=analysis_result["recommendations"],
            analysis_text=analysis_result["analysis"]
        )
        
    except Exception as e:
        print(f"ë·°í‹° ë¶„ì„ ë¹„êµ ì—ëŸ¬: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ë·°í‹° ë¶„ì„ ë¹„êµ ì‹¤íŒ¨: {str(e)}")

@app.post("/analyze-initial-beauty-score")
async def analyze_initial_beauty_score(request: InitialBeautyAnalysisRequest):
    """ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ GPT ë¶„ì„"""
    try:
        beauty_analysis = request.beauty_analysis
        
        # GPT-4o minië¥¼ ì‚¬ìš©í•œ ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ ë¶„ì„
        analysis_result = await get_gpt_initial_beauty_analysis(beauty_analysis)
        
        return InitialBeautyAnalysisResponse(
            analysis_text=analysis_result["analysis"],
            recommendations=analysis_result["recommendations"],
            strengths=analysis_result["strengths"],
            improvement_areas=analysis_result["improvement_areas"]
        )
        
    except Exception as e:
        print(f"ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ GPT ë¶„ì„ ì—ëŸ¬: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}")


def apply_warp(image: np.ndarray, start_x: float, start_y: float, 
               end_x: float, end_y: float, influence_radius: float, 
               strength: float, mode: str) -> np.ndarray:
    """ì›Œí•‘ ë³€í˜• ì ìš© í•¨ìˆ˜"""
    img_height, img_width = image.shape[:2]
    
    # ì¢Œí‘œ ê²½ê³„ ê²€ì‚¬
    start_x = max(0, min(start_x, img_width - 1))
    start_y = max(0, min(start_y, img_height - 1))
    end_x = max(0, min(end_x, img_width - 1))
    end_y = max(0, min(end_y, img_height - 1))
    
    print(f"ì›Œí•‘ ëª¨ë“œ: {mode}")
    if mode == "pull":
        return apply_pull_warp(image, start_x, start_y, end_x, end_y, influence_radius, strength)
    elif mode == "push":
        return apply_push_warp(image, start_x, start_y, end_x, end_y, influence_radius, strength)
    elif mode == "expand":
        print("í™•ëŒ€ ëª¨ë“œ ì‹¤í–‰ - expand=True")
        return apply_radial_warp(image, start_x, start_y, influence_radius, strength, expand=True)
    elif mode == "shrink":
        print("ì¶•ì†Œ ëª¨ë“œ ì‹¤í–‰ - expand=False")
        return apply_radial_warp(image, start_x, start_y, influence_radius, strength, expand=False)
    else:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {mode}")
        return image

def apply_pull_warp(image: np.ndarray, start_x: float, start_y: float,
                   end_x: float, end_y: float, influence_radius: float, strength: float, ellipse_ratio: float = None) -> np.ndarray:
    """ë‹¹ê¸°ê¸° ì›Œí•‘"""
    img_height, img_width = image.shape[:2]
    
    # ë“œë˜ê·¸ ë²¡í„° (ì˜ˆì „ ë°©ì‹: ë°˜ëŒ€ ë°©í–¥)
    dx = start_x - end_x
    dy = start_y - end_y
    
    # ë³€í˜• ë§µ ìƒì„±
    map_x = np.arange(img_width, dtype=np.float32).reshape(1, -1)
    map_y = np.arange(img_height, dtype=np.float32).reshape(-1, 1)
    map_x = np.repeat(map_x, img_height, axis=0)
    map_y = np.repeat(map_y, img_width, axis=1)
    
    # ê° í”½ì…€ì—ì„œ ì‹œì‘ì ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    pixel_dx = map_x - start_x
    pixel_dy = map_y - start_y
    pixel_dist = np.sqrt(pixel_dx*pixel_dx + pixel_dy*pixel_dy)
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­ ë§ˆìŠ¤í¬
    mask = pixel_dist < influence_radius
    
    # ë³€í˜• ê°•ë„ ê³„ì‚°
    strength_map = np.zeros_like(pixel_dist)
    valid_dist = pixel_dist[mask]
    
    if len(valid_dist) > 0:
        strength_map[mask] = (1 - valid_dist / influence_radius) ** 2
        strength_map[mask] *= strength
        
        # ë³€í˜• ì ìš©
        map_x[mask] += dx * strength_map[mask]
        map_y[mask] += dy * strength_map[mask]
    
    # ê²½ê³„ í´ë¦¬í•‘
    map_x = np.clip(map_x, 0, img_width - 1)
    map_y = np.clip(map_y, 0, img_height - 1)
    
    # ë¦¬ë§µí•‘ ì ìš©
    return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)

def apply_push_warp(image: np.ndarray, start_x: float, start_y: float,
                   end_x: float, end_y: float, influence_radius: float, strength: float) -> np.ndarray:
    """ë°€ì–´ë‚´ê¸° ì›Œí•‘"""
    img_height, img_width = image.shape[:2]
    
    # ë“œë˜ê·¸ ë²¡í„°
    dx = end_x - start_x
    dy = end_y - start_y
    
    # ë³€í˜• ë§µ ìƒì„±
    map_x = np.arange(img_width, dtype=np.float32).reshape(1, -1)
    map_y = np.arange(img_height, dtype=np.float32).reshape(-1, 1)
    map_x = np.repeat(map_x, img_height, axis=0)
    map_y = np.repeat(map_y, img_width, axis=1)
    
    # ê° í”½ì…€ì—ì„œ ì‹œì‘ì ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    pixel_dx = map_x - start_x
    pixel_dy = map_y - start_y
    pixel_dist = np.sqrt(pixel_dx*pixel_dx + pixel_dy*pixel_dy)
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­ ë§ˆìŠ¤í¬
    mask = pixel_dist < influence_radius
    
    # ë³€í˜• ê°•ë„ ê³„ì‚°
    strength_map = np.zeros_like(pixel_dist)
    valid_dist = pixel_dist[mask]
    
    if len(valid_dist) > 0:
        strength_map[mask] = (1 - valid_dist / influence_radius) ** 2
        strength_map[mask] *= strength
        
        # ë³€í˜• ì ìš©
        map_x[mask] += dx * strength_map[mask]
        map_y[mask] += dy * strength_map[mask]
    
    # ê²½ê³„ í´ë¦¬í•‘
    map_x = np.clip(map_x, 0, img_width - 1)
    map_y = np.clip(map_y, 0, img_height - 1)
    
    # ë¦¬ë§µí•‘ ì ìš©
    return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)


def apply_radial_warp(image: np.ndarray, center_x: float, center_y: float,
                     influence_radius: float, strength: float, expand: bool = True) -> np.ndarray:
    """ë°©ì‚¬í˜• ì›Œí•‘ (í™•ëŒ€/ì¶•ì†Œ)"""
    img_height, img_width = image.shape[:2]
    
    # ë³€í˜• ë§µ ìƒì„±
    map_x = np.arange(img_width, dtype=np.float32).reshape(1, -1)
    map_y = np.arange(img_height, dtype=np.float32).reshape(-1, 1)
    map_x = np.repeat(map_x, img_height, axis=0)
    map_y = np.repeat(map_y, img_width, axis=1)
    
    # ì¤‘ì‹¬ì ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ì™€ ê°ë„
    dx = map_x - center_x
    dy = map_y - center_y
    distance = np.sqrt(dx*dx + dy*dy)
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­
    mask = distance < influence_radius
    
    # ë³€í˜• ê³„ìˆ˜ ê³„ì‚°
    strength_factor = strength * 0.3
    
    if expand:
        # í™•ëŒ€: ì¤‘ì‹¬ìœ¼ë¡œ ê°€ê¹Œì›Œì§€ê²Œ (íŒ½ì°½ íš¨ê³¼)
        scale_factor = 1 - strength_factor * (1 - distance / influence_radius)
    else:
        # ì¶•ì†Œ: ì¤‘ì‹¬ì—ì„œ ë©€ì–´ì§€ê²Œ (ìˆ˜ì¶• íš¨ê³¼)
        scale_factor = 1 + strength_factor * (1 - distance / influence_radius)
    
    scale_factor = np.maximum(scale_factor, 0.1)  # ìµœì†Œ ìŠ¤ì¼€ì¼ ì œí•œ
    
    # ìƒˆë¡œìš´ ì¢Œí‘œ ê³„ì‚°
    new_x = center_x + dx * scale_factor
    new_y = center_y + dy * scale_factor
    
    # ì˜í–¥ë°›ëŠ” ì˜ì—­ë§Œ ì—…ë°ì´íŠ¸
    map_x = np.where(mask, new_x, map_x)
    map_y = np.where(mask, new_y, map_y)
    
    # ê²½ê³„ í´ë¦¬í•‘
    map_x = np.clip(map_x, 0, img_width - 1)
    map_y = np.clip(map_y, 0, img_height - 1)
    
    # ë¦¬ë§µí•‘ ì ìš©
    return cv2.remap(image, map_x, map_y, cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)


def apply_preset_transformation(image: np.ndarray, landmarks: List[Tuple[float, float]], preset_type: str) -> np.ndarray:
    """í”„ë¦¬ì…‹ ë³€í˜• ì ìš©"""
    print(f"\n=== PRESET DEBUG: {preset_type} ===")
    print(f"Image shape: {image.shape}")
    print(f"Total landmarks: {len(landmarks)}")
    
    # í”„ë¦¬ì…‹ ìƒìˆ˜ë“¤ (face_simulator.pyì—ì„œ ê°€ì ¸ì˜´)
    PRESET_CONFIGS = {
        'lower_jaw': {
            'strength': 0.05,
            'influence_ratio': 0.4,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (150, 379, 4)
        },
        'middle_jaw': {
            'strength': 0.05,
            'influence_ratio': 0.65,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (172, 397, 4)
        },
        'cheek': {
            'strength': 0.05,
            'influence_ratio': 0.65,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (215, 435, 4)
        },
        'front_protusion': {
            'strength': 0.3,
            'influence_ratio': 0.1,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (243, 463, (56, 190), (414, 286), 168, 6),
            'ellipse_ratio': 1.3
        },
        'back_slit': {
            'strength': 0.5,
            'influence_ratio': 0.1,
            'pull_ratio': 0.1,
            'face_size_landmarks': (234, 447),
            'target_landmarks': (33, 359, (34, 162), (368, 264))
        }
    }
    
    if preset_type not in PRESET_CONFIGS:
        raise ValueError(f"Unknown preset type: {preset_type}")
    
    config = PRESET_CONFIGS[preset_type]
    
    # ì–¼êµ´ í¬ê¸° ê³„ì‚°
    face_size_left = landmarks[config['face_size_landmarks'][0]]
    face_size_right = landmarks[config['face_size_landmarks'][1]]
    face_width = abs(face_size_right[0] - face_size_left[0])
    
    print(f"Face landmarks: left={face_size_left}, right={face_size_right}")
    print(f"Face width: {face_width}px")
    
    # ì˜í–¥ ë°˜ê²½ ê³„ì‚°
    influence_radius = face_width * config['influence_ratio']
    print(f"Influence radius: {influence_radius}px (ratio: {config['influence_ratio']})")
    print(f"Config: {config}")
    
    result_image = image.copy()
    
    if preset_type in ['lower_jaw', 'middle_jaw', 'cheek']:
        # ê¸°ë³¸ í„±ì„  í”„ë¦¬ì…‹ (ì¢Œìš° ëŒ€ì¹­)
        left_landmark = landmarks[config['target_landmarks'][0]]
        right_landmark = landmarks[config['target_landmarks'][1]]
        target_landmark = landmarks[config['target_landmarks'][2]]
        
        # ì¢Œì¸¡ ë³€í˜•
        distance_left = math.sqrt((left_landmark[0] - target_landmark[0])**2 + 
                                (left_landmark[1] - target_landmark[1])**2)
        pull_distance_left = distance_left * config['pull_ratio']
        
        dx_left = target_landmark[0] - left_landmark[0]
        dy_left = target_landmark[1] - left_landmark[1]
        norm_left = math.sqrt(dx_left**2 + dy_left**2)
        
        if norm_left > 0:
            dx_left = (dx_left / norm_left) * pull_distance_left
            dy_left = (dy_left / norm_left) * pull_distance_left
            
            target_x_left = left_landmark[0] + dx_left
            target_y_left = left_landmark[1] + dy_left
            
            result_image = apply_pull_warp(
                result_image,
                left_landmark[0], left_landmark[1],
                target_x_left, target_y_left,
                influence_radius, config['strength']
            )
        
        # ìš°ì¸¡ ë³€í˜•
        distance_right = math.sqrt((right_landmark[0] - target_landmark[0])**2 + 
                                 (right_landmark[1] - target_landmark[1])**2)
        pull_distance_right = distance_right * config['pull_ratio']
        
        dx_right = target_landmark[0] - right_landmark[0]
        dy_right = target_landmark[1] - right_landmark[1]
        norm_right = math.sqrt(dx_right**2 + dy_right**2)
        
        if norm_right > 0:
            dx_right = (dx_right / norm_right) * pull_distance_right
            dy_right = (dy_right / norm_right) * pull_distance_right
            
            target_x_right = right_landmark[0] + dx_right
            target_y_right = right_landmark[1] + dy_right
            
            result_image = apply_pull_warp(
                result_image,
                right_landmark[0], right_landmark[1],
                target_x_right, target_y_right,
                influence_radius, config['strength']
            )
    
    elif preset_type == 'front_protusion':
        # ì•íŠ¸ì„ í”„ë¦¬ì…‹ (4ê°œ í¬ì¸íŠ¸)
        landmark_243 = landmarks[243]
        landmark_463 = landmarks[463]
        
        print(f"\n--- FRONT PROTUSION DEBUG ---")
        print(f"Landmark 243 (left inner): {landmark_243}")
        print(f"Landmark 463 (right inner): {landmark_463}")
        
        # ì¤‘ê°„ì ë“¤ ê³„ì‚°
        mid_56_190 = ((landmarks[56][0] + landmarks[190][0]) / 2,
                      (landmarks[56][1] + landmarks[190][1]) / 2)
        mid_414_286 = ((landmarks[414][0] + landmarks[286][0]) / 2,
                       (landmarks[414][1] + landmarks[286][1]) / 2)
        
        print(f"Mid 56_190: {mid_56_190}")
        print(f"Mid 414_286: {mid_414_286}")
        
        # ì•íŠ¸ì„: ì˜ˆì „ ë°©ì‹ - ì½” ì¤‘ì‹¬ìœ¼ë¡œ ë‹¹ê¸°ê¸°
        # íƒ€ê²Ÿ ì¤‘ê°„ì  ê³„ì‚° (168 + 6ì˜ ì¤‘ê°„ì )
        target_mid = ((landmarks[168][0] + landmarks[6][0]) / 2,
                      (landmarks[168][1] + landmarks[6][1]) / 2)
        
        print(f"Target mid (nose center): {target_mid}")
        
        # ê° í¬ì¸íŠ¸ì— ë³€í˜• ì ìš© (ì½” ì¤‘ì‹¬ìœ¼ë¡œ)
        for i, (source_landmark, target_point) in enumerate([
            (landmark_243, target_mid),
            (landmark_463, target_mid),
            (mid_56_190, target_mid),
            (mid_414_286, target_mid)
        ]):
            distance = math.sqrt((source_landmark[0] - target_point[0])**2 + 
                               (source_landmark[1] - target_point[1])**2)
            pull_distance = distance * config['pull_ratio']
            
            dx = target_point[0] - source_landmark[0]
            dy = target_point[1] - source_landmark[1]
            norm = math.sqrt(dx**2 + dy**2)
            
            print(f"\nPoint {i+1}: {source_landmark} -> {target_point}")
            print(f"Distance: {distance:.2f}px")
            print(f"Pull ratio: {config['pull_ratio']}")
            print(f"Pull distance: {pull_distance:.2f}px")
            print(f"Direction vector: ({dx:.2f}, {dy:.2f})")
            
            if norm > 0:
                dx = (dx / norm) * pull_distance
                dy = (dy / norm) * pull_distance
                
                target_x = source_landmark[0] + dx
                target_y = source_landmark[1] + dy
                
                print(f"Normalized direction: ({dx:.2f}, {dy:.2f})")
                print(f"Final target: ({target_x:.2f}, {target_y:.2f})")
                print(f"Actual movement: ({dx:.2f}, {dy:.2f})")
                print(f"Strength: {config['strength']}")
                print(f"Influence radius: {influence_radius:.2f}px")
                print(f"Ellipse ratio: {config.get('ellipse_ratio')}")
                
                result_image = apply_pull_warp(
                    result_image,
                    source_landmark[0], source_landmark[1],
                    target_x, target_y,
                    influence_radius, config['strength'],
                    config.get('ellipse_ratio')
                )
    
    elif preset_type == 'back_slit':
        # ë’·íŠ¸ì„ í”„ë¦¬ì…‹
        landmark_33 = landmarks[33]
        landmark_359 = landmarks[359]
        
        # íƒ€ê²Ÿ ì¤‘ê°„ì ë“¤
        mid_34_162 = ((landmarks[34][0] + landmarks[162][0]) / 2,
                      (landmarks[34][1] + landmarks[162][1]) / 2)
        mid_368_264 = ((landmarks[368][0] + landmarks[264][0]) / 2,
                       (landmarks[368][1] + landmarks[264][1]) / 2)
        
        # ë³€í˜• ì ìš©
        for source_landmark, target_point in [
            (landmark_33, mid_34_162),
            (landmark_359, mid_368_264)
        ]:
            distance = math.sqrt((source_landmark[0] - target_point[0])**2 + 
                               (source_landmark[1] - target_point[1])**2)
            pull_distance = distance * config['pull_ratio']
            
            dx = target_point[0] - source_landmark[0]
            dy = target_point[1] - source_landmark[1]
            norm = math.sqrt(dx**2 + dy**2)
            
            if norm > 0:
                dx = (dx / norm) * pull_distance
                dy = (dy / norm) * pull_distance
                
                target_x = source_landmark[0] + dx
                target_y = source_landmark[1] + dy
                
                result_image = apply_pull_warp(
                    result_image,
                    source_landmark[0], source_landmark[1],
                    target_x, target_y,
                    influence_radius, config['strength'],
                    config.get('ellipse_ratio')
                )
    
    return result_image


async def get_gpt_beauty_analysis(before_analysis: Dict[str, Any], after_analysis: Dict[str, Any], score_changes: Dict[str, float]) -> Dict[str, Any]:
    """GPT-4o minië¥¼ ì‚¬ìš©í•œ ë·°í‹° ë¶„ì„ ë¹„êµ"""
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
        system_prompt = """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë·°í‹° ì»¨ì„¤í„´íŠ¸ì´ì ì„±í˜•ì™¸ê³¼ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì–¼êµ´ ë³€í˜• ì „í›„ì˜ ë·°í‹° ì ìˆ˜ë¥¼ ë¶„ì„í•˜ê³ , ê°œì„ ì‚¬í•­ê³¼ ì¶”ì²œì‚¬í•­ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ë¶„ì„ ê¸°ì¤€:
- ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨ (verticalScore): ì–¼êµ´ì˜ ê°€ë¡œ ë¹„ìœ¨ ê· í˜•
- ì„¸ë¡œ ëŒ€ì¹­ì„± (horizontalScore): ì–¼êµ´ì˜ ì„¸ë¡œ ëŒ€ì¹­ì„±
- í•˜ê´€ ì¡°í™” (lowerFaceScore): í•˜ê´€ë¶€ ì¡°í™”ë¡œì›€
- ì „ì²´ ëŒ€ì¹­ì„± (symmetry): ì¢Œìš° ëŒ€ì¹­ì„±
- ëˆˆ (eyeScore): ëˆˆì˜ í˜•íƒœì™€ ìœ„ì¹˜
- ì½” (noseScore): ì½”ì˜ í˜•íƒœì™€ ë¹„ìœ¨
- ì…ìˆ  (lipScore): ì…ìˆ ì˜ í˜•íƒœì™€ ë¹„ìœ¨
- í„± ê³¡ë¥  (jawScore): í„±ì„ ì˜ ê°ë„ì™€ ê³¡ë¥ 

ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ, ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        # ì ìˆ˜ ë³€í™” ìš”ì•½
        changes_summary = []
        for key, change in score_changes.items():
            if abs(change) > 0.5:  # 0.5ì  ì´ìƒ ë³€í™”ë§Œ í¬í•¨
                direction = "ìƒìŠ¹" if change > 0 else "í•˜ë½"
                changes_summary.append(f"{key}: {change:.1f}ì  {direction}")

        # ì•ˆì „í•œ ì ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
        def get_score(analysis, key, default=0):
            value = analysis.get(key, default)
            if isinstance(value, dict):
                return value.get('score', default)
            return value if isinstance(value, (int, float)) else default

        user_prompt = f"""
ë·°í‹° ì‹œìˆ  ì „í›„ ë¶„ì„ ê²°ê³¼:

ã€ì‹œìˆ  ì „ ì ìˆ˜ã€‘
- ì¢…í•©ì ìˆ˜: {get_score(before_analysis, 'overallScore'):.1f}ì 
- ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨: {get_score(before_analysis, 'verticalScore'):.1f}ì 
- ì„¸ë¡œ ëŒ€ì¹­ì„±: {get_score(before_analysis, 'horizontalScore'):.1f}ì 
- í•˜ê´€ ì¡°í™”: {get_score(before_analysis, 'lowerFaceScore'):.1f}ì 
- ì „ì²´ ëŒ€ì¹­ì„±: {get_score(before_analysis, 'symmetry'):.1f}ì 
- ëˆˆ: {get_score(before_analysis, 'eyeScore'):.1f}ì 
- ì½”: {get_score(before_analysis, 'noseScore'):.1f}ì 
- ì…ìˆ : {get_score(before_analysis, 'lipScore'):.1f}ì 
- í„± ê³¡ë¥ : {get_score(before_analysis, 'jawScore'):.1f}ì 

ã€ì‹œìˆ  í›„ ì ìˆ˜ã€‘
- ì¢…í•©ì ìˆ˜: {get_score(after_analysis, 'overallScore'):.1f}ì 
- ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨: {get_score(after_analysis, 'verticalScore'):.1f}ì 
- ì„¸ë¡œ ëŒ€ì¹­ì„±: {get_score(after_analysis, 'horizontalScore'):.1f}ì 
- í•˜ê´€ ì¡°í™”: {get_score(after_analysis, 'lowerFaceScore'):.1f}ì 
- ì „ì²´ ëŒ€ì¹­ì„±: {get_score(after_analysis, 'symmetry'):.1f}ì 
- ëˆˆ: {get_score(after_analysis, 'eyeScore'):.1f}ì 
- ì½”: {get_score(after_analysis, 'noseScore'):.1f}ì 
- ì…ìˆ : {get_score(after_analysis, 'lipScore'):.1f}ì 
- í„± ê³¡ë¥ : {get_score(after_analysis, 'jawScore'):.1f}ì 

ã€ì£¼ìš” ë³€í™”ã€‘
{', '.join(changes_summary) if changes_summary else 'í° ë³€í™” ì—†ìŒ'}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ì „ë°˜ì ì¸ ë³€í™” ìš”ì•½ (2-3ë¬¸ì¥)
2. í•­ëª©ë³„ ìƒì„¸ ë¶„ì„ (ê°œì„ ëœ ë¶€ë¶„, ì•„ì‰¬ìš´ ë¶€ë¶„)
3. ì¶”ê°€ ê°œì„  ì¶”ì²œì‚¬í•­ (3-4ê°œì˜ êµ¬ì²´ì ì¸ ì œì•ˆ)

ì¹œê·¼í•˜ê³  ê²©ë ¤ì ì¸ í†¤ìœ¼ë¡œ, í•˜ì§€ë§Œ ì „ë¬¸ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

        # GPT-4o mini í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=1000,
            temperature=0.7
        )

        analysis_text = response.choices[0].message.content or "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ì¶”ì²œì‚¬í•­ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
        recommendations = []
        if "ì¶”ì²œì‚¬í•­" in analysis_text or "ì œì•ˆ" in analysis_text:
            lines = analysis_text.split('\n')
            for line in lines:
                if any(keyword in line for keyword in ["ì¶”ì²œ", "ì œì•ˆ", "ê¶Œì¥", "ê³ ë ¤"]):
                    clean_line = line.strip().lstrip('-').lstrip('*').lstrip('â€¢').strip()
                    if len(clean_line) > 10:  # ì˜ë¯¸ìˆëŠ” ê¸¸ì´ì˜ ì¶”ì²œì‚¬í•­ë§Œ
                        recommendations.append(clean_line)

        # ê¸°ë³¸ ì¶”ì²œì‚¬í•­ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not recommendations:
            if score_changes.get('overall', 0) > 0:
                recommendations = [
                    "í˜„ì¬ ê°œì„ ì´ ì˜ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë°©í–¥ìœ¼ë¡œ ê³„ì† ì§„í–‰í•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
                    "ë‹¤ë¥¸ ë¶€ìœ„ì™€ì˜ ì¡°í™”ë¥¼ ê³ ë ¤í•œ ì¶”ê°€ì ì¸ ë¯¸ì„¸ ì¡°ì •ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.",
                    "ì •ê¸°ì ì¸ ì¬ì¸¡ì •ì„ í†µí•´ ë³€í™” ê³¼ì •ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”."
                ]
            else:
                recommendations = [
                    "í˜„ì¬ ì„¤ì •ì„ ì¬ê²€í† í•˜ê³  ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì„ ì‹œë„í•´ë³´ì„¸ìš”.",
                    "ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì—¬ ë§ì¶¤í˜• ê°œì„  ë°©ì•ˆì„ ì°¾ì•„ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.",
                    "ë‹¨ê³„ì ì¸ ì ‘ê·¼ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë³€í™”ë¥¼ ì¶”êµ¬í•˜ì„¸ìš”."
                ]

        return {
            "analysis": analysis_text,
            "recommendations": recommendations[:4]  # ìµœëŒ€ 4ê°œê¹Œì§€
        }

    except Exception as e:
        print(f"GPT ë¶„ì„ ì˜¤ë¥˜: {e}")
        # í´ë°± ì‘ë‹µ
        return {
            "analysis": "ì‹œìˆ  ì „í›„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì „ë¬¸ì ì¸ ë¶„ì„ì„ ìœ„í•´ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "recommendations": [
                "ë³€í™”ëœ ë¶€ë¶„ì„ ê¼¼ê¼¼íˆ ê´€ì°°í•´ë³´ì„¸ìš”.",
                "ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¼ë©´ í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì‹œê³ , ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•˜ë‹¤ë©´ ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ì„¸ìš”.",
                "ì •ê¸°ì ì¸ ì¬ì§„ë‹¨ì„ í†µí•´ ì§€ì†ì ì¸ ê°œì„ ì„ ì¶”êµ¬í•˜ì„¸ìš”."
            ]
        }


async def get_gpt_initial_beauty_analysis(beauty_analysis: Dict[str, Any]) -> Dict[str, Any]:
    """GPT-4o minië¥¼ ì‚¬ìš©í•œ ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ ë¶„ì„"""
    print(f"ğŸ” GPT ë¶„ì„ í•¨ìˆ˜ í˜¸ì¶œë¨")
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜ - ë¶„ì„ê³¼ êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²• ì—°ê²°
        system_prompt = """
ë‹¹ì‹ ì€ ë·°í‹° ë¶„ì„ê³¼ êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

**ëª©í‘œ**: ë¶„ì„í•œ ìˆ˜ì¹˜ì  ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ê°œì„  ë°©ë²•ì„ ì œì‹œ

**ì‘ë‹µ êµ¬ì¡°**:
1. **ê°„ë‹¨í•œ ë¶„ì„ ìš”ì•½** (2-3ì¤„)
2. **ë¶„ì„ ê²°ê³¼** (ì£¼ìš” ê°•ì ê³¼ ê°œì„ ì ì„ ìˆ˜ì¹˜ì™€ í•¨ê»˜)
3. **êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²• 3ê°€ì§€** (ë¶„ì„ì—ì„œ ì–¸ê¸‰í•œ ê°œì„ ì ê³¼ ì—°ê²°)

**ì‹¤ì²œ ë°©ë²• í˜•ì‹** (ê° í•­ëª©ë§ˆë‹¤):
- ğŸ¯ **ê°œì„  ëª©í‘œ**: [ë¶„ì„ì—ì„œ ì–¸ê¸‰í•œ êµ¬ì²´ì  ìˆ˜ì¹˜] â†’ [ëª©í‘œ ìˆ˜ì¹˜]
- ğŸ’ª **ìš´ë™/ìŠµê´€**: ë§¤ì¼ [ì‹œê°„]ë¶„ [êµ¬ì²´ì  ë°©ë²•]
ì¶”ì²œ ì‚¬ì´íŠ¸: [ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì´íŠ¸ëª…](https://www.ì‹¤ì œURL.com)
- ğŸ¥ **ì „ë¬¸ ê´€ë¦¬**: [ì‹œìˆ ëª…] [ì˜ˆìƒë¹„ìš©] [íš¨ê³¼ ì„¤ëª…]  
ì¶”ì²œ ë³‘ì›: [ì‹¤ì œ ë³‘ì›ëª…](https://www.ì‹¤ì œë³‘ì›URL.com)

**ì¤‘ìš”**: ì¶”ì²œí•˜ëŠ” ëª¨ë“  ì‚¬ì´íŠ¸ì™€ ë³‘ì› URLì€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ê³  ì ‘ì† ê°€ëŠ¥í•œ ê³³ë§Œ í¬í•¨í•˜ì„¸ìš”.
- ìš´ë™/ìŠµê´€: YouTube ì±„ë„, í”¼íŠ¸ë‹ˆìŠ¤ ì•±, ê±´ê°• ì •ë³´ ì‚¬ì´íŠ¸ ë“± ì‹¤ì œ ì´ìš© ê°€ëŠ¥í•œ ê³³
- ì „ë¬¸ ê´€ë¦¬: ì‹¤ì œ ì„±í˜•ì™¸ê³¼, í”¼ë¶€ê³¼, ì—ìŠ¤í…Œí‹± í´ë¦¬ë‹‰ ë“± ê³µì‹ í™ˆí˜ì´ì§€

**í•„ìˆ˜ ìš”êµ¬ì‚¬í•­**:
- ë¶„ì„ì—ì„œ ì–¸ê¸‰í•œ ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ ë°˜ë“œì‹œ í¬í•¨
- ê° ê°œì„ ì ë§ˆë‹¤ ìš´ë™+ì „ë¬¸ê´€ë¦¬ ëª¨ë‘ ì œì‹œ
- êµ¬ì²´ì  ì‹œê°„, ë¹„ìš©, ë°©ë²• ëª…ì‹œ
"""

        # ì•ˆì „í•œ ì ìˆ˜ ì¶”ì¶œ í•¨ìˆ˜
        def get_score(analysis, key, default=0):
            value = analysis.get(key, default)
            if isinstance(value, dict):
                return value.get('score', default)
            return value if isinstance(value, (int, float)) else default

        # ì‹¤ì œ ì¸¡ì •ëœ ì£¼ìš” ì–¼êµ´ ë¹„ìœ¨ ë¶„ì„ë§Œ í¬í•¨ (ëˆˆ/ì½”/ì…ìˆ  ì œì™¸)
        main_scores = {
            'overall': get_score(beauty_analysis, 'overallScore'),
            'vertical': get_score(beauty_analysis, 'verticalScore'),
            'horizontal': get_score(beauty_analysis, 'horizontalScore'),
            'lowerFace': get_score(beauty_analysis, 'lowerFaceScore'),
            'symmetry': get_score(beauty_analysis, 'symmetry'),
            'jaw': get_score(beauty_analysis, 'jawScore'),
        }

        # ê°•ì  í•­ëª© (80ì  ì´ìƒ)
        strengths = []
        # ê°œì„  ì˜ì—­ (70ì  ë¯¸ë§Œ)
        improvement_areas = []
        
        score_names = {
            'vertical': 'ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨',
            'horizontal': 'ì„¸ë¡œ ëŒ€ì¹­ì„±', 
            'lowerFace': 'í•˜ê´€ ì¡°í™”',
            'symmetry': 'ì „ì²´ ëŒ€ì¹­ì„±',
            'jaw': 'í„± ê³¡ë¥ '
        }
        
        for key, score in main_scores.items():
            if key == 'overall':
                continue
            name = score_names.get(key, key)
            if score >= 80:
                strengths.append(f"{name} ({score:.1f}ì )")
            elif score < 70:
                improvement_areas.append(f"{name} ({score:.1f}ì )")

        # ìƒì„¸ ë¶„ì„ ì •ë³´ ì¶”ì¶œ
        def get_detailed_info(key):
            value = beauty_analysis.get(key, {})
            if isinstance(value, dict):
                return value
            return {}

        vertical_info = get_detailed_info('verticalScore')
        horizontal_info = get_detailed_info('horizontalScore') 
        lowerface_info = get_detailed_info('lowerFaceScore')
        jaw_info = get_detailed_info('jawScore')

        # ìƒì„¸ ì ìˆ˜ì™€ ë¹„ìœ¨ ì •ë³´ êµ¬ì„±
        detailed_analysis = []
        
        # ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨ (5êµ¬ê°„ í¼ì„¼íŠ¸)
        if main_scores['vertical'] >= 10:
            analysis_text = f"ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨: {main_scores['vertical']:.1f}ì "
            if 'percentages' in vertical_info and vertical_info['percentages']:
                percentages = vertical_info['percentages']
                sections = ['ì™¼ìª½ë°”ê¹¥', 'ì™¼ìª½ëˆˆ', 'ë¯¸ê°„', 'ì˜¤ë¥¸ìª½ëˆˆ', 'ì˜¤ë¥¸ìª½ë°”ê¹¥']
                percent_details = []
                for i, pct in enumerate(percentages[:5]):
                    percent_details.append(f"{sections[i]} {pct:.1f}%")
                analysis_text += f" (êµ¬ê°„ë³„: {', '.join(percent_details)})"
            detailed_analysis.append(analysis_text)
        
        # ì„¸ë¡œ ëŒ€ì¹­ì„± (2êµ¬ê°„ í¼ì„¼íŠ¸)
        if main_scores['horizontal'] >= 10:
            analysis_text = f"ì„¸ë¡œ ëŒ€ì¹­ì„±: {main_scores['horizontal']:.1f}ì "
            if 'upperPercentage' in horizontal_info and 'lowerPercentage' in horizontal_info:
                upper = horizontal_info['upperPercentage']
                lower = horizontal_info['lowerPercentage']
                analysis_text += f" (ëˆˆ~ì½” {upper:.1f}%, ì½”~í„± {lower:.1f}%)"
            detailed_analysis.append(analysis_text)
        
        # í•˜ê´€ ì¡°í™” (2êµ¬ê°„ í¼ì„¼íŠ¸)
        if main_scores['lowerFace'] >= 10:
            analysis_text = f"í•˜ê´€ ì¡°í™”: {main_scores['lowerFace']:.1f}ì "
            if 'upperPercentage' in lowerface_info and 'lowerPercentage' in lowerface_info:
                upper = lowerface_info['upperPercentage']
                lower = lowerface_info['lowerPercentage']
                analysis_text += f" (ì¸ì¤‘ {upper:.1f}%, ì…~í„± {lower:.1f}%)"
            detailed_analysis.append(analysis_text)
        
        # ì „ì²´ ëŒ€ì¹­ì„±
        if main_scores['symmetry'] >= 10:
            detailed_analysis.append(f"ì „ì²´ ëŒ€ì¹­ì„±: {main_scores['symmetry']:.1f}ì ")
        
        # í„± ê³¡ë¥  (ê°ë„ ì •ë³´)
        if main_scores['jaw'] >= 10:
            analysis_text = f"í„± ê³¡ë¥ : {main_scores['jaw']:.1f}ì "
            if 'gonialAngle' in jaw_info and 'cervicoMentalAngle' in jaw_info:
                gonial = jaw_info['gonialAngle']
                cervico = jaw_info['cervicoMentalAngle']
                analysis_text += f" (í•˜ì•…ê° {gonial:.1f}Â°, í„±ëª©ê° {cervico:.1f}Â°)"
            detailed_analysis.append(analysis_text)
        
        # ê°œì„  í¬ì¸íŠ¸ë§Œ ì¶”ì¶œ (ì´ìƒì  ë²”ìœ„ì—ì„œ ë²—ì–´ë‚œ íŠ¹ì§•ì ì¸ ë¶€ë¶„)
        improvement_points = []
        
        # ê°€ë¡œ í™©ê¸ˆë¹„ìœ¨ ì²´í¬ (20%ì—ì„œ 3% ì´ìƒ ë²—ì–´ë‚œ ê²½ìš°)
        if 'percentages' in vertical_info and vertical_info['percentages']:
            percentages = vertical_info['percentages']
            sections = ['ì™¼ìª½ë°”ê¹¥', 'ì™¼ìª½ëˆˆ', 'ë¯¸ê°„', 'ì˜¤ë¥¸ìª½ëˆˆ', 'ì˜¤ë¥¸ìª½ë°”ê¹¥']
            for i, pct in enumerate(percentages[:5]):
                diff = abs(pct - 20.0)
                if diff > 3.0:
                    improvement_points.append(f"{sections[i]} {pct:.1f}% (ì´ìƒ 20%)")
        
        # ì„¸ë¡œ ëŒ€ì¹­ì„± ì²´í¬ (50:50ì—ì„œ 3% ì´ìƒ ë²—ì–´ë‚œ ê²½ìš°)
        if 'upperPercentage' in horizontal_info and 'lowerPercentage' in horizontal_info:
            upper = horizontal_info['upperPercentage']
            lower = horizontal_info['lowerPercentage']
            if abs(upper - 50.0) > 3.0:
                improvement_points.append(f"ìƒì•ˆë©´ {upper:.1f}% (ì´ìƒ 50%)")
        
        # í•˜ê´€ ì¡°í™” ì²´í¬ (33:67ì—ì„œ ë²—ì–´ë‚œ ê²½ìš°)
        if 'upperPercentage' in lowerface_info and 'lowerPercentage' in lowerface_info:
            upper = lowerface_info['upperPercentage']
            lower = lowerface_info['lowerPercentage']
            if abs(upper - 33.0) > 3.0:
                improvement_points.append(f"ì¸ì¤‘ {upper:.1f}% (ì´ìƒ 33%)")
        
        # í„± ê³¡ë¥  ì²´í¬ (90-120ë„ ë²”ìœ„ ë²—ì–´ë‚œ ê²½ìš°)
        if 'gonialAngle' in jaw_info:
            gonial = jaw_info['gonialAngle']
            if gonial < 90 or gonial > 120:
                improvement_points.append(f"í•˜ì•…ê° {gonial:.1f}Â° (ì´ìƒ 90-120Â°)")

        user_prompt = f"""
ì¸¡ì • ê²°ê³¼: ì¢…í•© {main_scores['overall']:.1f}ì 

ê°•ì  í•­ëª©: {', '.join(strengths) if strengths else 'ê· í˜• ì¡íŒ ì „ì²´ì  ë¹„ìœ¨'}
ê°œì„  í•­ëª©: {', '.join(improvement_areas) if improvement_areas else 'ì—†ìŒ'}

íŠ¹ì§•ì  ì¸¡ì •ê°’:
{chr(10).join(f"- {point}" for point in improvement_points) if improvement_points else "- ì „ì²´ì ìœ¼ë¡œ ì´ìƒì ì¸ ë¹„ìœ¨ ìœ ì§€"}

ë‹¤ìŒ 3ê°œ í•­ëª©ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ğŸŒŸ ë‚´ ì–¼êµ´ì˜ ì¢‹ì€ ì 
ì¸¡ì • ê²°ê³¼ ì¤‘ ì´ìƒì ì¸ ë²”ìœ„ì— ìˆê±°ë‚˜ ë§¤ë ¥ì ì¸ ë¶€ë¶„ì„ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.

2. ğŸ“Š ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„  
ì´ìƒì  ë²”ìœ„ì—ì„œ ë²—ì–´ë‚œ ë¶€ë¶„ì„ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
(ì˜ˆ: "í•˜ì•…ê°ì´ 133Â°ë¡œ ì´ìƒì  ë²”ìœ„ 90-120Â°ë³´ë‹¤ ì»¤ì„œ í„±ì„ ì´ ë¶€ë“œëŸ¬ìš´ í¸ì´ì—ìš”")

3. ğŸ’¡ ê°œì„  í›„ ê¸°ëŒ€íš¨ê³¼
ê°œì„ ë˜ë©´ ì–´ë–¤ ë§¤ë ¥ì ì¸ ë³€í™”ê°€ ìˆì„ì§€ í¬ë§ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

---

ìœ„ 2ë²ˆì—ì„œ ì–¸ê¸‰í•œ ê°œì„  í•„ìš” ë¶€ë¶„ì„ ì •í™•íˆ ì°¸ì¡°í•˜ì—¬ êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²•ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

ê° ê°œì„ ì ë§ˆë‹¤ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ:
ğŸ¯ **[2ë²ˆì—ì„œ ì–¸ê¸‰í•œ êµ¬ì²´ì  ë¬¸ì œ]** ê°œì„ 
ğŸ’ª **ìš´ë™/ìŠµê´€**: ë§¤ì¼ [ì‹œê°„]ë¶„ [êµ¬ì²´ì  ë°©ë²•] + ì¶”ì²œ ì‚¬ì´íŠ¸
ğŸ¥ **ì „ë¬¸ ê´€ë¦¬**: [ì‹œìˆ ëª…] [ì˜ˆìƒë¹„ìš©] [íš¨ê³¼]

ë°˜ë“œì‹œ 2ë²ˆ ë¶„ì„ì˜ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ë¬¸ì œì ì„ ì°¸ì¡°í•´ì„œ ì—°ê²°í•´ì£¼ì„¸ìš”.
"""

        # GPT-4o mini í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=1200,
            temperature=0.7
        )

        analysis_text = response.choices[0].message.content or "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ì¶”ì²œì‚¬í•­, ê°•ì , ê°œì„ ì˜ì—­ ì¶”ì¶œ
        recommendations = []
        strengths_list = []
        improvement_list = []

        # GPT í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì²œ ë°©ë²• ë¶€ë¶„ë§Œ ì¶”ì¶œ (--- ì´í›„ ì „ì²´ ë‚´ìš©)
        text_parts = analysis_text.split('---')
        
        if len(text_parts) >= 2:
            # --- ì´í›„ì˜ ëª¨ë“  ë‚´ìš©ì„ ì‹¤ì²œ ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©
            practice_section = text_parts[1].strip()
            
            # "### êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²•" ì œê±°í•˜ê³  ì‹¤ì œ ë‚´ìš©ë§Œ ì¶”ì¶œ
            practice_lines = practice_section.split('\n')
            cleaned_lines = []
            
            for line in practice_lines:
                line = line.strip()
                if not line:
                    cleaned_lines.append('')  # ë¹ˆ ì¤„ë„ ìœ ì§€
                    continue
                    
                # ì•ˆë‚´ ë¬¸êµ¬ë‚˜ í˜•ì‹ ì„¤ëª… ê±´ë„ˆë›°ê¸° (### ì œëª©ì€ ì œê±°)
                if any(skip_text in line for skip_text in [
                    "ìœ„ 2ë²ˆì—ì„œ ì–¸ê¸‰í•œ", "ê° ê°œì„ ì ë§ˆë‹¤", "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ", 
                    "ë°˜ë“œì‹œ 2ë²ˆ ë¶„ì„", "ì •í™•íˆ ì°¸ì¡°"
                ]) or line.startswith('### êµ¬ì²´ì  ì‹¤ì²œ ë°©ë²•'):
                    continue
                
                # ì‹¤ì œ ë‚´ìš©ë§Œ í¬í•¨ (ëª¨ë“  ğŸ¯, ğŸ’ª, ğŸ¥ ë‚´ìš©ê³¼ ì¼ë°˜ í…ìŠ¤íŠ¸)
                cleaned_lines.append(line)
            
            # ì‹¤ì²œ ë°©ë²• ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸° (Frontendì—ì„œ ê·¸ëŒ€ë¡œ í‘œì‹œ)
            if cleaned_lines:
                full_practice_content = '\n'.join(cleaned_lines).strip()
                recommendations = [full_practice_content]  # ì „ì²´ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ìš”ì†Œë¡œ
                
            print(f"ğŸ” Backend recommendations ê¸¸ì´: {len(recommendations[0]) if recommendations else 0}ì")
            print(f"ğŸ” Backend recommendations ìƒ˜í”Œ: {recommendations[0][:100] if recommendations else 'None'}...")
        else:
            print(f"ğŸ” Backend GPT ì‘ë‹µì— --- êµ¬ë¶„ì ì—†ìŒ: {analysis_text[:200]}...")
        
        # ê¸°ì¡´ ë¶„ì„ ë‚´ìš© ì¶”ì¶œ (1, 2, 3ë²ˆ ì„¹ì…˜ì—ì„œ)
        lines = analysis_text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            # ì„¹ì…˜ êµ¬ë¶„
            if any(keyword in line for keyword in ["ğŸŒŸ", "ì¢‹ì€ ì ", "ê°•ì "]):
                current_section = "strengths"
                continue
            elif any(keyword in line for keyword in ["ğŸ“Š", "ê°œì„ ì´ í•„ìš”í•œ", "ê°œì„  í•„ìš”"]):
                current_section = "improvements"
                continue
            elif "ğŸ’¡" in line or "ê¸°ëŒ€íš¨ê³¼" in line:
                current_section = "effects"
                continue
            elif "---" in line:
                # ì‹¤ì²œ ë°©ë²• ì„¹ì…˜ ì‹œì‘í•˜ë©´ ë¶„ì„ íŒŒì‹± ì¢…ë£Œ
                break
            
            # ê° ì„¹ì…˜ ë‚´ìš© ì¶”ì¶œ
            if line and (line.startswith('-') or line.startswith('â€¢') or line.startswith('*') or 
                        any(char.isdigit() for char in line[:3])):
                clean_line = line.lstrip('-').lstrip('*').lstrip('â€¢').strip()
                # ë²ˆí˜¸ ì œê±° (1., 2., 3. ë“±)
                if clean_line and clean_line[0].isdigit() and '.' in clean_line[:5]:
                    clean_line = clean_line.split('.', 1)[1].strip()
                
                if current_section == "strengths" and len(clean_line) > 10:
                    strengths_list.append(clean_line)
                elif current_section == "improvements" and len(clean_line) > 10:
                    improvement_list.append(clean_line)

        # ê¸°ë³¸ê°’ ì„¤ì •
        if not recommendations:
            if main_scores['overall'] >= 80:
                recommendations = [
                    "í˜„ì¬ ë§¤ìš° ê· í˜•ì¡íŒ ì•„ë¦„ë‹¤ìš´ ì–¼êµ´ì„ ê°€ì§€ê³  ê³„ì‹œë„¤ìš”.",
                    "ìì—°ìŠ¤ëŸ¬ìš´ ë©”ì´í¬ì—…ìœ¼ë¡œ ë³¸ì¸ì˜ ë§¤ë ¥ì„ ë”ìš± ë¶€ê°ì‹œì¼œë³´ì„¸ìš”.",
                    "ê±´ê°•í•œ ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì‹œë©´ ìì—°ìŠ¤ëŸ¬ìš´ ì•„ë¦„ë‹¤ì›€ì´ ì§€ì†ë  ê²ƒì…ë‹ˆë‹¤."
                ]
            elif main_scores['overall'] >= 70:
                recommendations = [
                    "ì´ë¯¸ ì¢‹ì€ ê¸°ë³¸ê¸°ë¥¼ ê°€ì§€ê³  ê³„ì‹œë‹ˆ ìì‹ ê°ì„ ê°€ì§€ì„¸ìš”.",
                    "í¬ì¸íŠ¸ ë©”ì´í¬ì—…ìœ¼ë¡œ ê°œì„±ì„ í‘œí˜„í•´ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
                    "ê·œì¹™ì ì¸ ìŠ¤í‚¨ì¼€ì–´ë¡œ í”¼ë¶€ ìƒíƒœë¥¼ ê°œì„ í•´ë³´ì„¸ìš”."
                ]
            else:
                recommendations = [
                    "ëª¨ë“  ì‚¬ëŒì€ ê³ ìœ í•œ ì•„ë¦„ë‹¤ì›€ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
                    "ìì‹ ë§Œì˜ ë§¤ë ¥ì ì¸ ìŠ¤íƒ€ì¼ì„ ì°¾ì•„ë³´ì„¸ìš”.",
                    "ë‹¨ê³„ì ì¸ ê´€ë¦¬ë¥¼ í†µí•´ ì ì§„ì ì¸ ê°œì„ ì„ ì¶”êµ¬í•˜ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
                ]

        if not strengths_list:
            strengths_list = [item for item in strengths] if strengths else ["ê³ ìœ í•œ ê°œì„±ê³¼ ë§¤ë ¥"]

        if not improvement_list:
            improvement_list = [item for item in improvement_areas] if improvement_areas else []

        result = {
            "analysis": analysis_text,
            "recommendations": recommendations[:4],
            "strengths": strengths_list[:3],
            "improvement_areas": improvement_list[:3]
        }
        print(f"ğŸ” Backend GPT ì‘ë‹µ: {result}")
        return result

    except Exception as e:
        print(f"ê¸°ì´ˆ ë·°í‹°ìŠ¤ì½”ì–´ GPT ë¶„ì„ ì˜¤ë¥˜: {e}")
        # í´ë°± ì‘ë‹µ
        return {
            "analysis": "ë·°í‹° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ë§Œì˜ ê³ ìœ í•œ ë§¤ë ¥ì„ ë°œê²¬í•˜ê³  ìì‹ ê°ì„ ê°€ì§€ì„¸ìš”!",
            "recommendations": [
                "ìì‹ ë§Œì˜ ë§¤ë ¥ì„ ì°¾ì•„ í‘œí˜„í•´ë³´ì„¸ìš”.",
                "ê±´ê°•í•œ ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì‹œë©´ ìì—°ìŠ¤ëŸ¬ìš´ ì•„ë¦„ë‹¤ì›€ì´ ë¹›ë‚  ê²ƒì…ë‹ˆë‹¤.",
                "ì •ê¸°ì ì¸ ê´€ë¦¬ë¡œ ê¾¸ì¤€í•œ ê°œì„ ì„ ì¶”êµ¬í•´ë³´ì„¸ìš”."
            ],
            "strengths": ["ê³ ìœ í•œ ê°œì„±"],
            "improvement_areas": []
        }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8083)